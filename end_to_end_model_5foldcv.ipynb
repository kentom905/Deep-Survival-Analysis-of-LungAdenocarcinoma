{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "end_to_end_model_5foldcv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV0cHtwLFpUS",
        "outputId": "79be6338-1074-483a-ccfe-e49484315346"
      },
      "source": [
        "''' Imports and loss function definitions  '''\n",
        "!pip install h5py\n",
        "!pip install lifelines\n",
        "import h5py\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from lifelines.utils import concordance_index\n",
        "import collections\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def nll_loss(hazards, S, Y, c, alpha=0.5, eps=1e-7):\n",
        "    batch_size = len(Y)\n",
        "    Y = Y.view(batch_size, 1) \n",
        "    c = c.view(batch_size, 1).float() \n",
        "    if S is None:\n",
        "        S = torch.cumprod(1 - hazards, dim=1)\n",
        "    S_padded = torch.cat([torch.ones_like(c), S], 1) \n",
        "    uncensored_loss = -(c) * (torch.log(torch.gather(S_padded, 1, Y).clamp(min=eps)) + torch.log(torch.gather(hazards, 1, Y).clamp(min=eps)))\n",
        "    censored_loss = - (1-c) * torch.log(torch.gather(S_padded, 1, Y+1).clamp(min=eps))\n",
        "    neg_l = censored_loss + uncensored_loss\n",
        "    loss = (1-alpha) * neg_l + alpha * uncensored_loss\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "def ce_loss(hazards, S, Y, c, alpha=0.4, eps=1e-7):\n",
        "    batch_size = len(Y)\n",
        "    Y = Y.view(batch_size, 1) \n",
        "    c = c.view(batch_size, 1).float() \n",
        "    if S is None:\n",
        "        S = torch.cumprod(1 - hazards, dim=1) \n",
        "    S_padded = torch.cat([torch.ones_like(c), S], 1)\n",
        "    reg = -(c) * (torch.log(torch.gather(S_padded, 1, Y)+eps) + torch.log(torch.gather(hazards, 1, Y).clamp(min=eps)))\n",
        "    ce_l = - (1-c) * torch.log(torch.gather(S, 1, Y).clamp(min=eps)) - (c) * torch.log(1 - torch.gather(S, 1, Y).clamp(min=eps))\n",
        "    loss = (1-alpha) * ce_l + alpha * reg\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "class CrossEntropySurvLoss(object):\n",
        "    def __init__(self, alpha=0.15):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __call__(self, hazards, S, Y, c, alpha=None): \n",
        "        if alpha is None:\n",
        "            return ce_loss(hazards, S, Y, c, alpha=self.alpha)\n",
        "        else:\n",
        "            return ce_loss(hazards, S, Y, c, alpha=alpha)\n",
        "\n",
        "class NLLSurvLoss(object):\n",
        "    def __init__(self, alpha=0.5):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __call__(self, hazards, S, Y, c, alpha=None):\n",
        "        if alpha is None:\n",
        "            return nll_loss(hazards, S, Y, c, alpha=self.alpha)\n",
        "        else:\n",
        "            return nll_loss(hazards, S, Y, c, alpha=alpha)\n",
        "\n",
        "class CoxSurvLoss(object):\n",
        "    def __call__(self,hazards, S, c, **kwargs):\n",
        "        current_batch_len = len(S)\n",
        "        R_mat = np.zeros([current_batch_len, current_batch_len], dtype=int)\n",
        "        for i in range(current_batch_len):\n",
        "            for j in range(current_batch_len):\n",
        "                R_mat[i,j] = S[0][j] >= S[0][i]\n",
        "    \n",
        "        R_mat = torch.FloatTensor(R_mat).to(device)\n",
        "        theta = hazards.reshape(-1)\n",
        "        exp_theta = torch.exp(theta)\n",
        "        loss_cox = -torch.mean((theta - torch.log(torch.sum(exp_theta*R_mat, dim=1))) * (c))\n",
        "        return loss_cox\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Collecting lifelines\n",
            "  Downloading lifelines-0.26.4-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.1.5)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (3.2.2)\n",
            "Collecting formulaic<0.3,>=0.2.2\n",
            "  Downloading formulaic-0.2.4-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting autograd-gamma>=0.3\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.19.5)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (0.8.1)\n",
            "Collecting interface-meta>=1.2\n",
            "  Downloading interface_meta-1.2.4-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.13.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines) (1.15.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4049 sha256=971775150132788627f82c663162544ef82f47dfa2f7223cf3fd95a15822698e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/01/ee/1331593abb5725ff7d8c1333aee93a50a1c29d6ddda9665c9f\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, formulaic, autograd-gamma, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-0.2.4 interface-meta-1.2.4 lifelines-0.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mBH2KD3F4Da",
        "outputId": "6b6ac122-2fec-452e-dc12-fb758c738cb9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qcgrqfF9hI"
      },
      "source": [
        "''' Attention Model definition suited for extracting survival/hazard rates '''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pdb\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.L = 1024\n",
        "        self.D = 128\n",
        "        self.K = 1\n",
        "\n",
        "        self.feature_extractor_part1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(20, 50, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.feature_extractor_part2 = nn.Sequential(\n",
        "            nn.Linear(50 * 53 * 53, self.L),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.L, self.D),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(self.D, self.K)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L*self.K, 4),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, **kwargs):\n",
        "        h = kwargs['x']\n",
        "        H = self.feature_extractor_part1(h)\n",
        "        H = H.view(-1, 50 * 53 * 53)\n",
        "        H = self.feature_extractor_part2(H)\n",
        "        A= self.attention(H)  \n",
        "        A = torch.transpose(A, 1, 0) \n",
        "        A_raw = A \n",
        "        A = F.softmax(A, dim=1)\n",
        "        M = torch.mm(A, H) \n",
        "        logits  = self.classifier(M) \n",
        "        Y_hat = torch.topk(logits, 1, dim = 1)[1]\n",
        "        hazards = torch.sigmoid(logits)\n",
        "        S = torch.cumprod(1 - hazards, dim=1)\n",
        "\n",
        "        \n",
        "        return hazards, S, Y_hat, A_raw\n",
        "\n",
        "\n",
        "       "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JDYSzhdF-cT"
      },
      "source": [
        "''' Input to model taken from filtered clinical dataset to include WSI patch, event observation and event duration. \n",
        "    It is to be noted that although the variable for event observation is defined as \"censor\" it contains value of event observation.\n",
        "    This particular definition is for the training phase '''\n",
        "class InputData(torch.utils.data.Dataset):\n",
        "    def __init__(self,train_image,valid_image,pos,censor='/content/drive/MyDrive/propro/train_valid_censor_1.pt',event_time='/content/drive/MyDrive/propro/train_valid_et_1.pt' ,mode = 'train', transform = None):\n",
        "        self.censor=censor\n",
        "        self.event_time=event_time\n",
        "        self.mode = mode\n",
        "        self.final_censor = torch.load(self.censor)\n",
        "        self.final_event_time = torch.load(self.event_time)\n",
        "        self.train_image = train_image\n",
        "        self.valid_image = valid_image\n",
        "        self.pos=pos\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()]) \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pos)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        temp_ind=self.pos[index]\n",
        "        if temp_ind>=0 and temp_ind<146926:\n",
        "          self.image=self.train_image\n",
        "          ind=temp_ind\n",
        "        elif temp_ind>=146926 and temp_ind<179709:\n",
        "          self.image=self.valid_image\n",
        "          ind=temp_ind-146926\n",
        "        preprocess = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "        img_test = transforms.ToPILImage()(self.image[ind]).convert(\"RGB\")\n",
        "        input_batch = preprocess(img_test)\n",
        "        censor = self.final_censor[index]\n",
        "        event_time = self.final_event_time[index]\n",
        "        \n",
        "        \n",
        "        \n",
        "        return (input_batch, censor,event_time)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xTQBQjpGCi0"
      },
      "source": [
        "''' Input to model taken from filtered clinical dataset to include WSI patch, event observation and event duration. \n",
        "    It is to be noted that although the variable for event observation is defined as \"censor\" it contains value of event observation.\n",
        "    This particular definition is for the testing/validation phase '''\n",
        "class InputTest(torch.utils.data.Dataset):\n",
        "    def __init__(self,image,censor='/content/drive/MyDrive/propro/test_censor_1.pt',event_time='/content/drive/MyDrive/propro/test_et_1.pt' ,mode = 'test', transform = None):\n",
        "        self.censor=censor\n",
        "        self.event_time=event_time\n",
        "        self.mode = mode\n",
        "        self.final_censor = torch.load(self.censor)\n",
        "        self.final_event_time = torch.load(self.event_time)\n",
        "        self.dset = image\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()]) \n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.dset)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        preprocess = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "        img_test = transforms.ToPILImage()(self.dset[index]).convert(\"RGB\")\n",
        "        input_batch = preprocess(img_test)\n",
        "        censor = self.final_censor[index]\n",
        "        event_time = self.final_event_time[index]\n",
        "        \n",
        "        \n",
        "        \n",
        "        return (input_batch, censor,event_time)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x7stDYQGFrT"
      },
      "source": [
        "''' Training is guided by a loss function that takes in survival information and optimizer updates after every 16 slides  '''\n",
        "def train_loop_survival(epoch, model, loader, optimizer, loss_fn=NLLSurvLoss(), gc=16):   \n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "    model.train()\n",
        "    train_loss_surv, train_loss = 0., 0.\n",
        "\n",
        "    print('\\n')\n",
        "    risk_scores = np.zeros((len(loader)))\n",
        "    observations = np.zeros((len(loader)))\n",
        "    event_times = np.zeros((len(loader)))\n",
        "\n",
        "    for batch_idx, (data_WSI,censor,event_time) in enumerate(loader):\n",
        "        if censor.item() == -1.0:\n",
        "            continue\n",
        "        model.train()\n",
        "        data_WSI= data_WSI.to(device)\n",
        "\n",
        "        hazards, S, Y_hat, _ = model(x=data_WSI) \n",
        "        c=censor.to(device)\n",
        "        loss = loss_fn(hazards,S,Y_hat,c) \n",
        "        loss_value = loss.item()\n",
        "\n",
        "\n",
        "        risk = -torch.sum(S, dim=1).detach().cpu().numpy()\n",
        "        risk_scores[batch_idx] = risk\n",
        "        observations[batch_idx] = c.item()\n",
        "        event_times[batch_idx] = event_time \n",
        "        \n",
        "\n",
        "        train_loss_surv += loss_value\n",
        "        train_loss += loss_value + loss_reg\n",
        "\n",
        "        if (batch_idx + 1) % 1000 == 0:\n",
        "            print('batch {}, loss: {:.4f}, risk: {:.4f}, bag_size: {}'.format(batch_idx, loss_value + loss_reg,float(risk), data_WSI.size(0)))\n",
        "\n",
        "        loss = loss / gc + loss_reg\n",
        "        loss.backward()\n",
        "\n",
        "        if (batch_idx + 1) % gc == 0: \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    train_loss_surv /= len(loader)\n",
        "    train_loss /= len(loader)\n",
        "    \n",
        "    c_index = concordance_index(event_times, risk_scores, event_observed=observations) \n",
        "\n",
        "    print('Epoch: {}, train_loss_surv: {:.4f}, train_loss: {:.4f}, train_c_index: {:.4f}'.format(epoch, train_loss_surv, train_loss, c_index))\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyed5-LQGo_7"
      },
      "source": [
        "''' Used for validation/testing '''\n",
        "def validate_survival(epoch, model, loader, loss_fn=NLLSurvLoss()):\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    val_loss_surv, val_loss = 0., 0.\n",
        "    risk_scores = np.zeros((len(loader)))\n",
        "    observations = np.zeros((len(loader)))\n",
        "    event_times = np.zeros((len(loader))) \n",
        "\n",
        "    for batch_idx, (data_WSI,censor,event_time) in enumerate(loader):\n",
        "        if censor.item() == -1.0:\n",
        "            continue\n",
        "        data_WSI = data_WSI.to(device)\n",
        "        c = censor.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            hazards, S, Y_hat, _ = model(x=data_WSI) \n",
        "\n",
        "        loss = loss_fn(hazards,S,Y_hat,c)\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        risk = -torch.sum(S, dim=1).cpu().numpy()\n",
        "        risk_scores[batch_idx] = risk\n",
        "        observations[batch_idx] = c.cpu().numpy()\n",
        "        event_times[batch_idx] = event_time\n",
        "\n",
        "        val_loss_surv += loss_value\n",
        "        val_loss += loss_value \n",
        "\n",
        "    val_loss_surv /= len(loader)\n",
        "    val_loss /= len(loader)\n",
        "\n",
        "    c_index = concordance_index(event_times, risk_scores, event_observed=observations) \n",
        "   \n",
        "    print('Epoch: {}, val_loss_surv: {:.4f}, val_loss: {:.4f}, val_c_index: {:.4f}'.format(epoch, val_loss_surv, val_loss, c_index))\n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgi_iA94GvRO",
        "outputId": "e0d01bb4-efda-4add-b6b3-ba5efc93d18a"
      },
      "source": [
        "'''  Clinical dataset being filtered for the purpose of survival resulting in 942 unique cases. This will be used to get the appropriate patchesin training and testing sets '''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "cols=[\"case_submitter_id\",\"days_to_birth\",\"days_to_death\",\"vital_status\",\"year_of_birth\",\"year_of_death\",\"age_at_diagnosis\",\"days_to_diagnosis\",\"days_to_last_follow_up\",\"year_of_diagnosis\",\"treatment_or_therapy\"]\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/propro/clinical.tsv\",usecols=cols, sep='\\t')\n",
        "temp1=pd.get_dummies(df[\"vital_status\"])\n",
        "df2 = pd.concat((df,temp1),axis=1)\n",
        "df2 = df2.drop(['vital_status'],axis=1)\n",
        "df2 = df2.drop(['Alive'],axis=1)\n",
        "df2['Dead'] = df2['Dead'].astype(int)\n",
        "df2 = df2.drop_duplicates()\n",
        "df2 = df2.replace(\"'--\", np.nan)\n",
        "df2['event_data'] = df2['days_to_death']\n",
        "df2.event_data.fillna(df2.days_to_last_follow_up, inplace=True)\n",
        "df2 = df2[df2['event_data'].notna()]\n",
        "df2['duration_months'] = np.round(df2['event_data'].astype(int)/31)\n",
        "df2['duration_months']=df2['duration_months'].astype(int)\n",
        "df2=df2.sort_values([\"duration_months\"], ascending=True)\n",
        "df3 = df2[['case_submitter_id', 'Dead', 'event_data','duration_months']].copy()\n",
        "df3.reset_index(drop=True, inplace=True)\n",
        "df3=df3.drop_duplicates()\n",
        "len(df3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpP_L6rG8FS"
      },
      "source": [
        "''' Function to generate 5 folds of training and test splits in such a way that the event durations are uniformly distributed '''\n",
        "def get_folds_bins(frame, n_bins=5, eps=1e-6, num_folds=5):\n",
        "    def get_folds_event_data(frame, k, event_col):\n",
        "        df = frame.copy(deep=True)\n",
        "        df = df.reindex(np.random.permutation(df.index)).sort_values(event_col)\n",
        "        n, _ = df.shape\n",
        "\n",
        "        assignments = np.array((n // k + 1) * list(range(1, k + 1)))\n",
        "        assignments = assignments[:n]\n",
        "\n",
        "        folds = list()\n",
        "        for i in range(1, k+1):\n",
        "            ix = assignments == i\n",
        "            training_data = df.loc[~ix]\n",
        "            test_data     = df.loc[ix]\n",
        "            training_pat  = pd.unique(training_data.case_submitter_id).tolist()\n",
        "            test_pat  = pd.unique(test_data.case_submitter_id).tolist()\n",
        "            folds.append((training_pat,test_pat))\n",
        "        return folds\n",
        "\n",
        "    frame_working = frame.copy(deep=True)\n",
        "    uncensored_df = frame_working[frame_working.Dead== 1]\n",
        "\n",
        "    disc_labels, q_bins = pd.qcut(uncensored_df['duration_months'], q=n_bins, retbins=True, labels=False)\n",
        "    q_bins[-1] = frame_working['duration_months'].max() + eps\n",
        "    q_bins[0] = frame_working['duration_months'].min() - eps\n",
        "\n",
        "    disc_labels, q_bins = pd.cut(frame_working['duration_months'], bins=q_bins, retbins=True, labels=False, right=False, include_lowest=True)\n",
        "    frame_working.insert(2, 'label', disc_labels.values.astype(int))\n",
        "\n",
        "    total_folds = dict()\n",
        "    for i in range(num_folds):\n",
        "        total_folds[i] = dict()\n",
        "        total_folds[i]['train'] = list()\n",
        "        total_folds[i]['valid'] = list()\n",
        "        total_folds[i]['test'] = list()\n",
        "\n",
        "    for i in range(len(q_bins)-1):\n",
        "        bin_censored   = frame_working[(frame_working.label==i)&(frame_working.Dead==0)]\n",
        "        bin_uncensored = frame_working[(frame_working.label==i)&(frame_working.Dead==1)]\n",
        "        bin_folds_censored   = get_folds_event_data(frame=bin_censored,   k=num_folds, event_col='duration_months')\n",
        "        bin_folds_uncensored = get_folds_event_data(frame=bin_uncensored, k=num_folds, event_col='duration_months')\n",
        "\n",
        "        for i in range(num_folds):\n",
        "            total_folds[i]['train'].extend([pat for pat in bin_folds_censored[i][0]] + [pat for pat in bin_folds_uncensored[i][0]])\n",
        "            total_folds[i]['test'].extend([pat for pat in bin_folds_censored[i][1]] + [pat for pat in bin_folds_uncensored[i][1]])  \n",
        "    return total_folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBkDcMQaG-le"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqeOPXbHA9h"
      },
      "source": [
        "''' Input patches and unique ID stored in variables '''\n",
        "import h5py\n",
        "train = \"/content/drive/MyDrive/propro/hdf5_TCGAFFPE_LUAD_5x_perP_he_train.h5\"\n",
        "test = \"/content/drive/MyDrive/propro/hdf5_TCGAFFPE_LUAD_5x_perP_he_test.h5\"\n",
        "valid = \"/content/drive/MyDrive/propro/hdf5_TCGAFFPE_LUAD_5x_perP_he_validation.h5\"\n",
        "hdf5_train = h5py.File(train, \"r\")\n",
        "hdf5_test = h5py.File(test, \"r\")\n",
        "hdf5_valid = h5py.File(valid, \"r\")\n",
        "dtrain = hdf5_train['train_img']\n",
        "dtest = hdf5_test['test_img']\n",
        "dvalid = hdf5_valid['valid_img']\n",
        "train_slides = hdf5_train['train_slides']\n",
        "test_slides = hdf5_test['test_slides']\n",
        "valid_slides = hdf5_valid['valid_slides']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9T9clLjHDEB",
        "outputId": "f599bbec-7a3c-4723-e629-1754d7e507c5"
      },
      "source": [
        "data=get_folds_bins(df3)\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': ['TCGA-NK-A7XE',\n",
              "  'TCGA-37-3789',\n",
              "  'TCGA-56-A5DR',\n",
              "  'TCGA-66-2763',\n",
              "  'TCGA-99-8032',\n",
              "  'TCGA-56-8503',\n",
              "  'TCGA-55-8616',\n",
              "  'TCGA-66-2737',\n",
              "  'TCGA-56-8622',\n",
              "  'TCGA-MN-A4N5',\n",
              "  'TCGA-37-5819',\n",
              "  'TCGA-73-4670',\n",
              "  'TCGA-66-2795',\n",
              "  'TCGA-94-8035',\n",
              "  'TCGA-56-8083',\n",
              "  'TCGA-69-7761',\n",
              "  'TCGA-51-4080',\n",
              "  'TCGA-94-7557',\n",
              "  'TCGA-77-A5GB',\n",
              "  'TCGA-86-8672',\n",
              "  'TCGA-L9-A5IP',\n",
              "  'TCGA-MP-A4TC',\n",
              "  'TCGA-34-2596',\n",
              "  'TCGA-66-2773',\n",
              "  'TCGA-86-A4D0',\n",
              "  'TCGA-34-8455',\n",
              "  'TCGA-52-7809',\n",
              "  'TCGA-33-A4WN',\n",
              "  'TCGA-85-6798',\n",
              "  'TCGA-55-6978',\n",
              "  'TCGA-37-4132',\n",
              "  'TCGA-68-7757',\n",
              "  'TCGA-71-6725',\n",
              "  'TCGA-44-A47B',\n",
              "  'TCGA-49-6761',\n",
              "  'TCGA-05-4422',\n",
              "  'TCGA-67-3774',\n",
              "  'TCGA-69-7764',\n",
              "  'TCGA-69-8254',\n",
              "  'TCGA-44-A4SS',\n",
              "  'TCGA-66-2769',\n",
              "  'TCGA-55-6979',\n",
              "  'TCGA-85-8481',\n",
              "  'TCGA-21-1081',\n",
              "  'TCGA-22-4609',\n",
              "  'TCGA-85-8277',\n",
              "  'TCGA-MP-A4TD',\n",
              "  'TCGA-46-3768',\n",
              "  'TCGA-50-6593',\n",
              "  'TCGA-MP-A4TJ',\n",
              "  'TCGA-49-4490',\n",
              "  'TCGA-85-8584',\n",
              "  'TCGA-60-2697',\n",
              "  'TCGA-56-8201',\n",
              "  'TCGA-55-7725',\n",
              "  'TCGA-67-6217',\n",
              "  'TCGA-46-6026',\n",
              "  'TCGA-38-6178',\n",
              "  'TCGA-90-7964',\n",
              "  'TCGA-05-4417',\n",
              "  'TCGA-56-8082',\n",
              "  'TCGA-97-7941',\n",
              "  'TCGA-55-A494',\n",
              "  'TCGA-85-8351',\n",
              "  'TCGA-96-8170',\n",
              "  'TCGA-55-8094',\n",
              "  'TCGA-55-8510',\n",
              "  'TCGA-55-8203',\n",
              "  'TCGA-95-A4VN',\n",
              "  'TCGA-55-A57B',\n",
              "  'TCGA-56-5898',\n",
              "  'TCGA-05-4403',\n",
              "  'TCGA-43-7656',\n",
              "  'TCGA-55-7994',\n",
              "  'TCGA-96-A4JK',\n",
              "  'TCGA-85-7950',\n",
              "  'TCGA-05-4405',\n",
              "  'TCGA-56-7221',\n",
              "  'TCGA-97-A4M5',\n",
              "  'TCGA-67-3771',\n",
              "  'TCGA-98-8023',\n",
              "  'TCGA-L9-A743',\n",
              "  'TCGA-94-7033',\n",
              "  'TCGA-43-6770',\n",
              "  'TCGA-55-A48X',\n",
              "  'TCGA-69-7763',\n",
              "  'TCGA-66-2788',\n",
              "  'TCGA-44-6148',\n",
              "  'TCGA-93-A4JN',\n",
              "  'TCGA-MP-A4TH',\n",
              "  'TCGA-85-8052',\n",
              "  'TCGA-66-2786',\n",
              "  'TCGA-97-7554',\n",
              "  'TCGA-56-7223',\n",
              "  'TCGA-22-1012',\n",
              "  'TCGA-49-4505',\n",
              "  'TCGA-55-7816',\n",
              "  'TCGA-L3-A524',\n",
              "  'TCGA-77-8138',\n",
              "  'TCGA-43-5668',\n",
              "  'TCGA-98-A53A',\n",
              "  'TCGA-85-A4JC',\n",
              "  'TCGA-22-4607',\n",
              "  'TCGA-78-7148',\n",
              "  'TCGA-98-A53D',\n",
              "  'TCGA-22-0940',\n",
              "  'TCGA-85-8666',\n",
              "  'TCGA-73-4659',\n",
              "  'TCGA-22-4595',\n",
              "  'TCGA-60-2725',\n",
              "  'TCGA-55-8513',\n",
              "  'TCGA-94-8491',\n",
              "  'TCGA-86-8671',\n",
              "  'TCGA-77-8144',\n",
              "  'TCGA-64-5779',\n",
              "  'TCGA-05-5425',\n",
              "  'TCGA-85-7844',\n",
              "  'TCGA-44-7671',\n",
              "  'TCGA-51-4081',\n",
              "  'TCGA-52-7810',\n",
              "  'TCGA-56-7580',\n",
              "  'TCGA-60-2721',\n",
              "  'TCGA-86-8076',\n",
              "  'TCGA-56-7823',\n",
              "  'TCGA-63-A5MY',\n",
              "  'TCGA-J2-A4AE',\n",
              "  'TCGA-58-A46M',\n",
              "  'TCGA-85-8580',\n",
              "  'TCGA-77-8156',\n",
              "  'TCGA-44-3398',\n",
              "  'TCGA-MN-A4N4',\n",
              "  'TCGA-66-2787',\n",
              "  'TCGA-44-2664',\n",
              "  'TCGA-78-7220',\n",
              "  'TCGA-18-5595',\n",
              "  'TCGA-33-AASL',\n",
              "  'TCGA-49-4487',\n",
              "  'TCGA-77-6842',\n",
              "  'TCGA-85-A4CL',\n",
              "  'TCGA-55-7227',\n",
              "  'TCGA-18-3416',\n",
              "  'TCGA-85-7699',\n",
              "  'TCGA-86-7711',\n",
              "  'TCGA-60-2715',\n",
              "  'TCGA-39-5034',\n",
              "  'TCGA-38-4627',\n",
              "  'TCGA-64-1681',\n",
              "  'TCGA-78-7152',\n",
              "  'TCGA-44-2662',\n",
              "  'TCGA-95-7039',\n",
              "  'TCGA-64-5778',\n",
              "  'TCGA-44-2657',\n",
              "  'TCGA-44-2656',\n",
              "  'TCGA-55-1595',\n",
              "  'TCGA-05-4249',\n",
              "  'TCGA-49-6743',\n",
              "  'TCGA-49-4514',\n",
              "  'TCGA-NC-A5HI',\n",
              "  'TCGA-97-7553',\n",
              "  'TCGA-77-A5G8',\n",
              "  'TCGA-NK-A5CT',\n",
              "  'TCGA-77-8148',\n",
              "  'TCGA-55-6980',\n",
              "  'TCGA-63-7021',\n",
              "  'TCGA-49-AAR2',\n",
              "  'TCGA-78-8655',\n",
              "  'TCGA-64-1679',\n",
              "  'TCGA-75-6206',\n",
              "  'TCGA-64-5774',\n",
              "  'TCGA-55-6983',\n",
              "  'TCGA-63-A5MB',\n",
              "  'TCGA-39-5019',\n",
              "  'TCGA-38-4626',\n",
              "  'TCGA-78-7149',\n",
              "  'TCGA-77-A5G3',\n",
              "  'TCGA-49-AARQ',\n",
              "  'TCGA-50-6597',\n",
              "  'TCGA-22-5477',\n",
              "  'TCGA-55-6981',\n",
              "  'TCGA-22-4594',\n",
              "  'TCGA-75-6212',\n",
              "  'TCGA-77-8150',\n",
              "  'TCGA-77-8009',\n",
              "  'TCGA-O1-A52J',\n",
              "  'TCGA-34-2600',\n",
              "  'TCGA-75-5125',\n",
              "  'TCGA-50-5045',\n",
              "  'TCGA-43-7658',\n",
              "  'TCGA-MP-A4SV',\n",
              "  'TCGA-33-4538',\n",
              "  'TCGA-77-A5FZ'],\n",
              " 'train': ['TCGA-77-7141',\n",
              "  'TCGA-05-4410',\n",
              "  'TCGA-55-8506',\n",
              "  'TCGA-63-A5M9',\n",
              "  'TCGA-NJ-A55A',\n",
              "  'TCGA-86-8281',\n",
              "  'TCGA-37-3792',\n",
              "  'TCGA-37-4141',\n",
              "  'TCGA-05-4244',\n",
              "  'TCGA-NJ-A55O',\n",
              "  'TCGA-56-A5DS',\n",
              "  'TCGA-35-3615',\n",
              "  'TCGA-66-2756',\n",
              "  'TCGA-85-7710',\n",
              "  'TCGA-66-2766',\n",
              "  'TCGA-91-A4BC',\n",
              "  'TCGA-86-8074',\n",
              "  'TCGA-NC-A5HH',\n",
              "  'TCGA-66-2753',\n",
              "  'TCGA-66-2744',\n",
              "  'TCGA-85-7843',\n",
              "  'TCGA-66-2755',\n",
              "  'TCGA-55-A493',\n",
              "  'TCGA-NJ-A4YP',\n",
              "  'TCGA-66-2765',\n",
              "  'TCGA-66-2754',\n",
              "  'TCGA-66-2768',\n",
              "  'TCGA-66-2767',\n",
              "  'TCGA-85-8355',\n",
              "  'TCGA-92-8065',\n",
              "  'TCGA-66-2777',\n",
              "  'TCGA-66-2785',\n",
              "  'TCGA-05-5715',\n",
              "  'TCGA-56-8305',\n",
              "  'TCGA-56-8304',\n",
              "  'TCGA-95-8494',\n",
              "  'TCGA-60-2720',\n",
              "  'TCGA-68-7755',\n",
              "  'TCGA-92-7341',\n",
              "  'TCGA-92-7340',\n",
              "  'TCGA-85-A5B5',\n",
              "  'TCGA-55-7727',\n",
              "  'TCGA-37-3783',\n",
              "  'TCGA-38-A44F',\n",
              "  'TCGA-69-8255',\n",
              "  'TCGA-92-8063',\n",
              "  'TCGA-NK-A5CX',\n",
              "  'TCGA-46-3769',\n",
              "  'TCGA-86-8056',\n",
              "  'TCGA-66-2781',\n",
              "  'TCGA-NC-A5HK',\n",
              "  'TCGA-69-7978',\n",
              "  'TCGA-05-5423',\n",
              "  'TCGA-92-8064',\n",
              "  'TCGA-67-6216',\n",
              "  'TCGA-69-7765',\n",
              "  'TCGA-94-8490',\n",
              "  'TCGA-86-6851',\n",
              "  'TCGA-98-A539',\n",
              "  'TCGA-93-8067',\n",
              "  'TCGA-69-7974',\n",
              "  'TCGA-67-6215',\n",
              "  'TCGA-35-4123',\n",
              "  'TCGA-NC-A5HD',\n",
              "  'TCGA-33-A5GW',\n",
              "  'TCGA-56-7731',\n",
              "  'TCGA-05-4395',\n",
              "  'TCGA-XC-AA0X',\n",
              "  'TCGA-51-4079',\n",
              "  'TCGA-77-7338',\n",
              "  'TCGA-NJ-A4YI',\n",
              "  'TCGA-93-A4JO',\n",
              "  'TCGA-97-7938',\n",
              "  'TCGA-34-7107',\n",
              "  'TCGA-73-4677',\n",
              "  'TCGA-22-5478',\n",
              "  'TCGA-85-8287',\n",
              "  'TCGA-50-6673',\n",
              "  'TCGA-22-4596',\n",
              "  'TCGA-98-A53B',\n",
              "  'TCGA-39-5028',\n",
              "  'TCGA-64-5775',\n",
              "  'TCGA-22-1011',\n",
              "  'TCGA-39-5030',\n",
              "  'TCGA-85-8353',\n",
              "  'TCGA-NC-A5HL',\n",
              "  'TCGA-55-A490',\n",
              "  'TCGA-44-2666',\n",
              "  'TCGA-98-8020',\n",
              "  'TCGA-95-7562',\n",
              "  'TCGA-18-4086',\n",
              "  'TCGA-05-4415',\n",
              "  'TCGA-66-2789',\n",
              "  'TCGA-50-6591',\n",
              "  'TCGA-86-8055',\n",
              "  'TCGA-05-4250',\n",
              "  'TCGA-18-3407',\n",
              "  'TCGA-NC-A5HF',\n",
              "  'TCGA-55-6975',\n",
              "  'TCGA-22-1002',\n",
              "  'TCGA-43-6773',\n",
              "  'TCGA-60-2696',\n",
              "  'TCGA-MP-A4T8',\n",
              "  'TCGA-66-2791',\n",
              "  'TCGA-34-5929',\n",
              "  'TCGA-18-3410',\n",
              "  'TCGA-MP-A4T7',\n",
              "  'TCGA-43-6771',\n",
              "  'TCGA-55-8092',\n",
              "  'TCGA-85-8352',\n",
              "  'TCGA-56-7730',\n",
              "  'TCGA-77-A5G7',\n",
              "  'TCGA-55-7914',\n",
              "  'TCGA-78-7146',\n",
              "  'TCGA-77-8007',\n",
              "  'TCGA-78-7158',\n",
              "  'TCGA-55-6712',\n",
              "  'TCGA-18-4083',\n",
              "  'TCGA-L9-A443',\n",
              "  'TCGA-69-7973',\n",
              "  'TCGA-68-7756',\n",
              "  'TCGA-69-7760',\n",
              "  'TCGA-35-4122',\n",
              "  'TCGA-44-7662',\n",
              "  'TCGA-37-4135',\n",
              "  'TCGA-68-8250',\n",
              "  'TCGA-37-4129',\n",
              "  'TCGA-37-4133',\n",
              "  'TCGA-37-4130',\n",
              "  'TCGA-43-7657',\n",
              "  'TCGA-44-8119',\n",
              "  'TCGA-35-5375',\n",
              "  'TCGA-46-6025',\n",
              "  'TCGA-L9-A444',\n",
              "  'TCGA-43-A475',\n",
              "  'TCGA-86-8585',\n",
              "  'TCGA-44-A47G',\n",
              "  'TCGA-43-A474',\n",
              "  'TCGA-44-A47F',\n",
              "  'TCGA-85-A53L',\n",
              "  'TCGA-43-A56V',\n",
              "  'TCGA-70-6722',\n",
              "  'TCGA-56-5897',\n",
              "  'TCGA-95-7944',\n",
              "  'TCGA-46-3766',\n",
              "  'TCGA-70-6723',\n",
              "  'TCGA-86-A4P7',\n",
              "  'TCGA-55-8619',\n",
              "  'TCGA-69-7979',\n",
              "  'TCGA-46-3767',\n",
              "  'TCGA-69-7980',\n",
              "  'TCGA-L3-A4E7',\n",
              "  'TCGA-43-8115',\n",
              "  'TCGA-LA-A446',\n",
              "  'TCGA-68-8251',\n",
              "  'TCGA-55-8507',\n",
              "  'TCGA-56-A4BX',\n",
              "  'TCGA-46-3765',\n",
              "  'TCGA-77-8145',\n",
              "  'TCGA-33-AASB',\n",
              "  'TCGA-22-0944',\n",
              "  'TCGA-71-8520',\n",
              "  'TCGA-O2-A52W',\n",
              "  'TCGA-78-7166',\n",
              "  'TCGA-05-4402',\n",
              "  'TCGA-55-7284',\n",
              "  'TCGA-49-AAR9',\n",
              "  'TCGA-78-7536',\n",
              "  'TCGA-05-4418',\n",
              "  'TCGA-60-2712',\n",
              "  'TCGA-49-4507',\n",
              "  'TCGA-73-4676',\n",
              "  'TCGA-85-6175',\n",
              "  'TCGA-05-5429',\n",
              "  'TCGA-52-7811',\n",
              "  'TCGA-78-7161',\n",
              "  'TCGA-78-7542',\n",
              "  'TCGA-78-8660',\n",
              "  'TCGA-66-2793',\n",
              "  'TCGA-50-7109',\n",
              "  'TCGA-90-A59Q',\n",
              "  'TCGA-60-2698',\n",
              "  'TCGA-56-8625',\n",
              "  'TCGA-4B-A93V',\n",
              "  'TCGA-05-4396',\n",
              "  'TCGA-56-8626',\n",
              "  'TCGA-21-5787',\n",
              "  'TCGA-55-7907',\n",
              "  'TCGA-18-3412',\n",
              "  'TCGA-77-7138',\n",
              "  'TCGA-38-4631',\n",
              "  'TCGA-73-A9RS',\n",
              "  'TCGA-77-8140',\n",
              "  'TCGA-O2-A5IB',\n",
              "  'TCGA-MP-A4TF',\n",
              "  'TCGA-63-A5MN',\n",
              "  'TCGA-22-5482',\n",
              "  'TCGA-18-3406',\n",
              "  'TCGA-MF-A522',\n",
              "  'TCGA-50-6594',\n",
              "  'TCGA-22-4613',\n",
              "  'TCGA-O2-A52S',\n",
              "  'TCGA-55-8620',\n",
              "  'TCGA-66-2780',\n",
              "  'TCGA-60-2726',\n",
              "  'TCGA-77-8131',\n",
              "  'TCGA-86-6562',\n",
              "  'TCGA-44-A4SU',\n",
              "  'TCGA-LA-A7SW',\n",
              "  'TCGA-85-8288',\n",
              "  'TCGA-NC-A5HJ',\n",
              "  'TCGA-22-4604',\n",
              "  'TCGA-94-A4VJ',\n",
              "  'TCGA-56-8309',\n",
              "  'TCGA-67-4679',\n",
              "  'TCGA-53-7813',\n",
              "  'TCGA-86-8668',\n",
              "  'TCGA-L4-A4E6',\n",
              "  'TCGA-56-A62T',\n",
              "  'TCGA-55-6543',\n",
              "  'TCGA-97-8179',\n",
              "  'TCGA-69-8253',\n",
              "  'TCGA-05-4384',\n",
              "  'TCGA-55-8505',\n",
              "  'TCGA-56-8624',\n",
              "  'TCGA-67-3773',\n",
              "  'TCGA-68-A59J',\n",
              "  'TCGA-43-A56U',\n",
              "  'TCGA-55-8615',\n",
              "  'TCGA-55-8302',\n",
              "  'TCGA-L9-A8F4',\n",
              "  'TCGA-73-4668',\n",
              "  'TCGA-55-8097',\n",
              "  'TCGA-55-8087',\n",
              "  'TCGA-85-8479',\n",
              "  'TCGA-44-A47A',\n",
              "  'TCGA-85-A512',\n",
              "  'TCGA-05-5420',\n",
              "  'TCGA-95-7948',\n",
              "  'TCGA-95-7947',\n",
              "  'TCGA-85-A510',\n",
              "  'TCGA-68-A59I',\n",
              "  'TCGA-63-A5MT',\n",
              "  'TCGA-56-8629',\n",
              "  'TCGA-NK-A5D1',\n",
              "  'TCGA-56-8504',\n",
              "  'TCGA-44-A479',\n",
              "  'TCGA-85-A50Z',\n",
              "  'TCGA-97-8177',\n",
              "  'TCGA-94-A5I4',\n",
              "  'TCGA-55-7573',\n",
              "  'TCGA-55-8614',\n",
              "  'TCGA-S2-AA1A',\n",
              "  'TCGA-93-7348',\n",
              "  'TCGA-55-8301',\n",
              "  'TCGA-56-8308',\n",
              "  'TCGA-93-A4JQ',\n",
              "  'TCGA-94-A5I6',\n",
              "  'TCGA-97-A4M3',\n",
              "  'TCGA-55-8621',\n",
              "  'TCGA-55-7911',\n",
              "  'TCGA-55-8204',\n",
              "  'TCGA-49-6745',\n",
              "  'TCGA-55-8514',\n",
              "  'TCGA-97-8172',\n",
              "  'TCGA-96-8169',\n",
              "  'TCGA-55-8511',\n",
              "  'TCGA-56-A4ZK',\n",
              "  'TCGA-97-7937',\n",
              "  'TCGA-L9-A7SV',\n",
              "  'TCGA-97-8175',\n",
              "  'TCGA-94-7943',\n",
              "  'TCGA-97-8171',\n",
              "  'TCGA-95-7567',\n",
              "  'TCGA-55-7903',\n",
              "  'TCGA-98-A53I',\n",
              "  'TCGA-67-3772',\n",
              "  'TCGA-97-A4M6',\n",
              "  'TCGA-55-A492',\n",
              "  'TCGA-93-A4JP',\n",
              "  'TCGA-44-6145',\n",
              "  'TCGA-NJ-A55R',\n",
              "  'TCGA-56-7582',\n",
              "  'TCGA-97-A4M1',\n",
              "  'TCGA-85-8049',\n",
              "  'TCGA-69-A59K',\n",
              "  'TCGA-J1-A4AH',\n",
              "  'TCGA-85-A4QR',\n",
              "  'TCGA-66-2778',\n",
              "  'TCGA-44-7660',\n",
              "  'TCGA-L4-A4E5',\n",
              "  'TCGA-66-2771',\n",
              "  'TCGA-55-8091',\n",
              "  'TCGA-56-A4BW',\n",
              "  'TCGA-91-A4BD',\n",
              "  'TCGA-55-8205',\n",
              "  'TCGA-95-A4VP',\n",
              "  'TCGA-98-A53H',\n",
              "  'TCGA-97-A4LX',\n",
              "  'TCGA-97-8552',\n",
              "  'TCGA-55-8508',\n",
              "  'TCGA-67-3770',\n",
              "  'TCGA-NJ-A7XG',\n",
              "  'TCGA-05-4382',\n",
              "  'TCGA-55-A4DG',\n",
              "  'TCGA-98-A53J',\n",
              "  'TCGA-55-A491',\n",
              "  'TCGA-55-A48Y',\n",
              "  'TCGA-56-8628',\n",
              "  'TCGA-97-A4M7',\n",
              "  'TCGA-55-7283',\n",
              "  'TCGA-86-7954',\n",
              "  'TCGA-90-A4ED',\n",
              "  'TCGA-97-A4M2',\n",
              "  'TCGA-95-A4VK',\n",
              "  'TCGA-56-A4ZJ',\n",
              "  'TCGA-98-7454',\n",
              "  'TCGA-55-A48Z',\n",
              "  'TCGA-97-A4M0',\n",
              "  'TCGA-37-A5EN',\n",
              "  'TCGA-66-2742',\n",
              "  'TCGA-99-AA5R',\n",
              "  'TCGA-44-6774',\n",
              "  'TCGA-60-2695',\n",
              "  'TCGA-55-7726',\n",
              "  'TCGA-66-2758',\n",
              "  'TCGA-86-8358',\n",
              "  'TCGA-56-6545',\n",
              "  'TCGA-56-A49D',\n",
              "  'TCGA-05-4425',\n",
              "  'TCGA-44-7659',\n",
              "  'TCGA-90-A4EE',\n",
              "  'TCGA-93-7347',\n",
              "  'TCGA-85-8350',\n",
              "  'TCGA-22-A5C4',\n",
              "  'TCGA-55-7576',\n",
              "  'TCGA-55-8208',\n",
              "  'TCGA-05-5428',\n",
              "  'TCGA-49-6767',\n",
              "  'TCGA-44-6775',\n",
              "  'TCGA-J2-8194',\n",
              "  'TCGA-86-8280',\n",
              "  'TCGA-43-6143',\n",
              "  'TCGA-66-2770',\n",
              "  'TCGA-44-6146',\n",
              "  'TCGA-44-7672',\n",
              "  'TCGA-44-6144',\n",
              "  'TCGA-55-7724',\n",
              "  'TCGA-66-2790',\n",
              "  'TCGA-55-7728',\n",
              "  'TCGA-60-2724',\n",
              "  'TCGA-99-7458',\n",
              "  'TCGA-J2-8192',\n",
              "  'TCGA-05-4245',\n",
              "  'TCGA-05-4433',\n",
              "  'TCGA-66-2783',\n",
              "  'TCGA-43-6647',\n",
              "  'TCGA-86-8073',\n",
              "  'TCGA-85-A4PA',\n",
              "  'TCGA-05-4430',\n",
              "  'TCGA-05-4432',\n",
              "  'TCGA-55-7815',\n",
              "  'TCGA-63-A5MP',\n",
              "  'TCGA-66-2759',\n",
              "  'TCGA-85-8048',\n",
              "  'TCGA-33-4586',\n",
              "  'TCGA-22-5474',\n",
              "  'TCGA-50-5931',\n",
              "  'TCGA-55-A4DF',\n",
              "  'TCGA-NC-A5HQ',\n",
              "  'TCGA-86-8359',\n",
              "  'TCGA-L9-A50W',\n",
              "  'TCGA-MP-A4TI',\n",
              "  'TCGA-05-4434',\n",
              "  'TCGA-55-8299',\n",
              "  'TCGA-21-1078',\n",
              "  'TCGA-55-6970',\n",
              "  'TCGA-85-A511',\n",
              "  'TCGA-22-1000',\n",
              "  'TCGA-63-A5MM',\n",
              "  'TCGA-50-5939',\n",
              "  'TCGA-95-7043',\n",
              "  'TCGA-22-5492',\n",
              "  'TCGA-49-6742',\n",
              "  'TCGA-44-6779',\n",
              "  'TCGA-39-5040',\n",
              "  'TCGA-66-2727',\n",
              "  'TCGA-56-7822',\n",
              "  'TCGA-34-5241',\n",
              "  'TCGA-85-8664',\n",
              "  'TCGA-56-7222',\n",
              "  'TCGA-44-7661',\n",
              "  'TCGA-39-5039',\n",
              "  'TCGA-55-7913',\n",
              "  'TCGA-22-5483',\n",
              "  'TCGA-56-A4BY',\n",
              "  'TCGA-J2-A4AD',\n",
              "  'TCGA-MP-A4TK',\n",
              "  'TCGA-62-A46P',\n",
              "  'TCGA-78-7147',\n",
              "  'TCGA-78-7154',\n",
              "  'TCGA-44-7669',\n",
              "  'TCGA-55-8090',\n",
              "  'TCGA-77-7140',\n",
              "  'TCGA-64-1677',\n",
              "  'TCGA-86-7714',\n",
              "  'TCGA-50-5044',\n",
              "  'TCGA-55-8512',\n",
              "  'TCGA-22-4591',\n",
              "  'TCGA-78-7150',\n",
              "  'TCGA-99-8033',\n",
              "  'TCGA-56-8623',\n",
              "  'TCGA-43-2578',\n",
              "  'TCGA-86-8075',\n",
              "  'TCGA-60-2707',\n",
              "  'TCGA-77-A5G6',\n",
              "  'TCGA-78-7160',\n",
              "  'TCGA-49-AAQV',\n",
              "  'TCGA-55-8096',\n",
              "  'TCGA-55-8089',\n",
              "  'TCGA-55-1592',\n",
              "  'TCGA-18-3414',\n",
              "  'TCGA-77-6845',\n",
              "  'TCGA-39-5029',\n",
              "  'TCGA-05-4397',\n",
              "  'TCGA-86-A4JF',\n",
              "  'TCGA-NC-A5HP',\n",
              "  'TCGA-55-6984',\n",
              "  'TCGA-44-2668',\n",
              "  'TCGA-85-8071',\n",
              "  'TCGA-73-4666',\n",
              "  'TCGA-86-A4P8',\n",
              "  'TCGA-86-8674',\n",
              "  'TCGA-05-4426',\n",
              "  'TCGA-56-8307',\n",
              "  'TCGA-05-4427',\n",
              "  'TCGA-69-8453',\n",
              "  'TCGA-78-7539',\n",
              "  'TCGA-NC-A5HT',\n",
              "  'TCGA-44-6147',\n",
              "  'TCGA-98-A53C',\n",
              "  'TCGA-MN-A4N1',\n",
              "  'TCGA-43-5670',\n",
              "  'TCGA-44-5645',\n",
              "  'TCGA-55-7570',\n",
              "  'TCGA-83-5908',\n",
              "  'TCGA-95-8039',\n",
              "  'TCGA-96-A4JL',\n",
              "  'TCGA-98-A538',\n",
              "  'TCGA-64-5815',\n",
              "  'TCGA-44-7670',\n",
              "  'TCGA-44-5644',\n",
              "  'TCGA-55-7281',\n",
              "  'TCGA-52-7622',\n",
              "  'TCGA-86-8673',\n",
              "  'TCGA-37-A5EM',\n",
              "  'TCGA-05-4420',\n",
              "  'TCGA-55-8206',\n",
              "  'TCGA-85-A513',\n",
              "  'TCGA-62-A472',\n",
              "  'TCGA-05-4424',\n",
              "  'TCGA-66-2792',\n",
              "  'TCGA-55-7995',\n",
              "  'TCGA-58-A46N',\n",
              "  'TCGA-55-8085',\n",
              "  'TCGA-60-2722',\n",
              "  'TCGA-86-A456',\n",
              "  'TCGA-55-5899',\n",
              "  'TCGA-98-8021',\n",
              "  'TCGA-85-A4JB',\n",
              "  'TCGA-86-8669',\n",
              "  'TCGA-86-8278',\n",
              "  'TCGA-85-8072',\n",
              "  'TCGA-86-8279',\n",
              "  'TCGA-85-7698',\n",
              "  'TCGA-85-8070',\n",
              "  'TCGA-86-7701',\n",
              "  'TCGA-21-A5DI',\n",
              "  'TCGA-85-8354',\n",
              "  'TCGA-J2-A4AG',\n",
              "  'TCGA-55-8207',\n",
              "  'TCGA-86-7953',\n",
              "  'TCGA-43-3920',\n",
              "  'TCGA-77-7465',\n",
              "  'TCGA-34-A5IX',\n",
              "  'TCGA-85-A4CN',\n",
              "  'TCGA-44-5643',\n",
              "  'TCGA-44-3918',\n",
              "  'TCGA-21-5786',\n",
              "  'TCGA-85-8276',\n",
              "  'TCGA-99-8025',\n",
              "  'TCGA-85-7697',\n",
              "  'TCGA-55-7910',\n",
              "  'TCGA-60-2723',\n",
              "  'TCGA-86-7955',\n",
              "  'TCGA-63-A5MV',\n",
              "  'TCGA-53-A4EZ',\n",
              "  'TCGA-44-7667',\n",
              "  'TCGA-85-7696',\n",
              "  'TCGA-44-3396',\n",
              "  'TCGA-64-1680',\n",
              "  'TCGA-50-8457',\n",
              "  'TCGA-05-4390',\n",
              "  'TCGA-50-8459',\n",
              "  'TCGA-99-8028',\n",
              "  'TCGA-86-7713',\n",
              "  'TCGA-44-2661',\n",
              "  'TCGA-85-8582',\n",
              "  'TCGA-86-8054',\n",
              "  'TCGA-43-2581',\n",
              "  'TCGA-55-1594',\n",
              "  'TCGA-64-1678',\n",
              "  'TCGA-73-7498',\n",
              "  'TCGA-34-8454',\n",
              "  'TCGA-77-A5GH',\n",
              "  'TCGA-44-3917',\n",
              "  'TCGA-NC-A5HM',\n",
              "  'TCGA-43-2576',\n",
              "  'TCGA-34-5928',\n",
              "  'TCGA-85-6561',\n",
              "  'TCGA-NC-A5HR',\n",
              "  'TCGA-55-6969',\n",
              "  'TCGA-55-6985',\n",
              "  'TCGA-62-A471',\n",
              "  'TCGA-77-8143',\n",
              "  'TCGA-38-7271',\n",
              "  'TCGA-44-4112',\n",
              "  'TCGA-78-7145',\n",
              "  'TCGA-85-A50M',\n",
              "  'TCGA-52-7812',\n",
              "  'TCGA-77-A5GF',\n",
              "  'TCGA-22-1016',\n",
              "  'TCGA-49-AAR4',\n",
              "  'TCGA-49-4488',\n",
              "  'TCGA-56-1622',\n",
              "  'TCGA-38-4629',\n",
              "  'TCGA-34-2605',\n",
              "  'TCGA-49-4512',\n",
              "  'TCGA-49-4510',\n",
              "  'TCGA-MP-A4TE',\n",
              "  'TCGA-53-7626',\n",
              "  'TCGA-85-A4QQ',\n",
              "  'TCGA-22-5485',\n",
              "  'TCGA-73-4675',\n",
              "  'TCGA-98-8022',\n",
              "  'TCGA-78-7535',\n",
              "  'TCGA-34-2604',\n",
              "  'TCGA-56-7579',\n",
              "  'TCGA-22-4605',\n",
              "  'TCGA-21-5782',\n",
              "  'TCGA-MP-A4TA',\n",
              "  'TCGA-78-7156',\n",
              "  'TCGA-21-1079',\n",
              "  'TCGA-55-7574',\n",
              "  'TCGA-44-6777',\n",
              "  'TCGA-O2-A52N',\n",
              "  'TCGA-55-6982',\n",
              "  'TCGA-49-4506',\n",
              "  'TCGA-44-3919',\n",
              "  'TCGA-53-7624',\n",
              "  'TCGA-58-A46K',\n",
              "  'TCGA-22-4593',\n",
              "  'TCGA-21-1077',\n",
              "  'TCGA-22-4601',\n",
              "  'TCGA-38-4630',\n",
              "  'TCGA-18-3417',\n",
              "  'TCGA-49-4494',\n",
              "  'TCGA-75-6214',\n",
              "  'TCGA-33-AAS8',\n",
              "  'TCGA-77-8128',\n",
              "  'TCGA-60-2704',\n",
              "  'TCGA-22-4599',\n",
              "  'TCGA-49-AARN',\n",
              "  'TCGA-37-A5EL',\n",
              "  'TCGA-MP-A4T2',\n",
              "  'TCGA-43-3394',\n",
              "  'TCGA-78-7155',\n",
              "  'TCGA-77-8136',\n",
              "  'TCGA-78-7540',\n",
              "  'TCGA-78-8648',\n",
              "  'TCGA-62-A470',\n",
              "  'TCGA-49-AARE',\n",
              "  'TCGA-21-5784',\n",
              "  'TCGA-85-6560',\n",
              "  'TCGA-60-2711',\n",
              "  'TCGA-97-7546',\n",
              "  'TCGA-77-A5GA',\n",
              "  'TCGA-60-2719',\n",
              "  'TCGA-44-2665',\n",
              "  'TCGA-66-2734',\n",
              "  'TCGA-75-5147',\n",
              "  'TCGA-44-2655',\n",
              "  'TCGA-NC-A5HO',\n",
              "  'TCGA-44-2659',\n",
              "  'TCGA-63-A5ML',\n",
              "  'TCGA-55-6971',\n",
              "  'TCGA-NJ-A4YQ',\n",
              "  'TCGA-05-4398',\n",
              "  'TCGA-50-5066',\n",
              "  'TCGA-66-2800',\n",
              "  'TCGA-NC-A5HN',\n",
              "  'TCGA-60-2716',\n",
              "  'TCGA-3H-AB3X',\n",
              "  'TCGA-60-2709',\n",
              "  'TCGA-60-2714',\n",
              "  'TCGA-18-5592',\n",
              "  'TCGA-34-5240',\n",
              "  'TCGA-64-5781',\n",
              "  'TCGA-63-6202',\n",
              "  'TCGA-50-5946',\n",
              "  'TCGA-63-A5MW',\n",
              "  'TCGA-66-2794',\n",
              "  'TCGA-49-6744',\n",
              "  'TCGA-63-7023',\n",
              "  'TCGA-39-5037',\n",
              "  'TCGA-60-2713',\n",
              "  'TCGA-58-A46L',\n",
              "  'TCGA-64-1676',\n",
              "  'TCGA-63-A5MI',\n",
              "  'TCGA-77-8154',\n",
              "  'TCGA-63-A5MJ',\n",
              "  'TCGA-50-5942',\n",
              "  'TCGA-44-6778',\n",
              "  'TCGA-22-5471',\n",
              "  'TCGA-21-1076',\n",
              "  'TCGA-49-AAR3',\n",
              "  'TCGA-97-7552',\n",
              "  'TCGA-33-6738',\n",
              "  'TCGA-97-7547',\n",
              "  'TCGA-NC-A5HG',\n",
              "  'TCGA-78-7159',\n",
              "  'TCGA-77-8153',\n",
              "  'TCGA-60-2710',\n",
              "  'TCGA-63-A5MH',\n",
              "  'TCGA-63-7022',\n",
              "  'TCGA-39-5035',\n",
              "  'TCGA-55-1596',\n",
              "  'TCGA-62-A46U',\n",
              "  'TCGA-63-7020',\n",
              "  'TCGA-21-1075',\n",
              "  'TCGA-63-A5MG',\n",
              "  'TCGA-55-6987',\n",
              "  'TCGA-NJ-A4YF',\n",
              "  'TCGA-39-5036',\n",
              "  'TCGA-62-A46V',\n",
              "  'TCGA-77-7142',\n",
              "  'TCGA-MP-A5C7',\n",
              "  'TCGA-NJ-A4YG',\n",
              "  'TCGA-NC-A5HE',\n",
              "  'TCGA-75-5146',\n",
              "  'TCGA-63-A5MS',\n",
              "  'TCGA-33-4547',\n",
              "  'TCGA-60-2708',\n",
              "  'TCGA-55-6642',\n",
              "  'TCGA-34-5232',\n",
              "  'TCGA-39-5024',\n",
              "  'TCGA-73-4662',\n",
              "  'TCGA-NK-A5CR',\n",
              "  'TCGA-80-5611',\n",
              "  'TCGA-58-A46J',\n",
              "  'TCGA-44-6776',\n",
              "  'TCGA-18-3421',\n",
              "  'TCGA-63-A5MR',\n",
              "  'TCGA-80-5608',\n",
              "  'TCGA-18-3419',\n",
              "  'TCGA-60-2706',\n",
              "  'TCGA-38-4625',\n",
              "  'TCGA-21-1072',\n",
              "  'TCGA-75-7027',\n",
              "  'TCGA-39-5027',\n",
              "  'TCGA-77-8139',\n",
              "  'TCGA-77-8146',\n",
              "  'TCGA-55-6986',\n",
              "  'TCGA-75-7025',\n",
              "  'TCGA-18-3411',\n",
              "  'TCGA-78-7153',\n",
              "  'TCGA-21-1070',\n",
              "  'TCGA-21-1082',\n",
              "  'TCGA-21-1080',\n",
              "  'TCGA-18-3409',\n",
              "  'TCGA-49-AARO',\n",
              "  'TCGA-39-5016',\n",
              "  'TCGA-77-A5G1',\n",
              "  'TCGA-39-5011',\n",
              "  'TCGA-33-4533',\n",
              "  'TCGA-77-7139',\n",
              "  'TCGA-18-4721',\n",
              "  'TCGA-49-AAR0',\n",
              "  'TCGA-77-8130',\n",
              "  'TCGA-49-AARR',\n",
              "  'TCGA-78-8640',\n",
              "  'TCGA-78-7163',\n",
              "  'TCGA-MP-A4T9',\n",
              "  'TCGA-55-6968',\n",
              "  'TCGA-50-6590',\n",
              "  'TCGA-21-1083',\n",
              "  'TCGA-O2-A52V',\n",
              "  'TCGA-33-AASI',\n",
              "  'TCGA-66-2757',\n",
              "  'TCGA-38-4632',\n",
              "  'TCGA-49-4501',\n",
              "  'TCGA-77-7463',\n",
              "  'TCGA-21-1071',\n",
              "  'TCGA-62-A46O',\n",
              "  'TCGA-50-5068',\n",
              "  'TCGA-MP-A4SY',\n",
              "  'TCGA-22-1017',\n",
              "  'TCGA-38-4628',\n",
              "  'TCGA-73-7499',\n",
              "  'TCGA-78-7633',\n",
              "  'TCGA-73-4658',\n",
              "  'TCGA-78-7537',\n",
              "  'TCGA-77-8133',\n",
              "  'TCGA-62-A46S',\n",
              "  'TCGA-55-6972',\n",
              "  'TCGA-39-5022',\n",
              "  'TCGA-22-5491',\n",
              "  'TCGA-96-7545',\n",
              "  'TCGA-62-A46R',\n",
              "  'TCGA-MP-A4SW',\n",
              "  'TCGA-MP-A4T6',\n",
              "  'TCGA-39-5031',\n",
              "  'TCGA-50-5055',\n",
              "  'TCGA-51-6867',\n",
              "  'TCGA-22-5489',\n",
              "  'TCGA-22-5473',\n",
              "  'TCGA-22-1005',\n",
              "  'TCGA-22-5472',\n",
              "  'TCGA-39-5021',\n",
              "  'TCGA-77-7335',\n",
              "  'TCGA-22-5480',\n",
              "  'TCGA-96-7544',\n",
              "  'TCGA-77-6843',\n",
              "  'TCGA-33-AASD',\n",
              "  'TCGA-18-3408',\n",
              "  'TCGA-77-6844',\n",
              "  'TCGA-22-5481',\n",
              "  'TCGA-MP-A4T4',\n",
              "  'TCGA-77-8008',\n",
              "  'TCGA-22-5479',\n",
              "  'TCGA-78-7167',\n",
              "  'TCGA-21-5783',\n",
              "  'TCGA-18-3415',\n",
              "  'TCGA-60-2703',\n",
              "  'TCGA-33-4582',\n",
              "  'TCGA-77-7337',\n",
              "  'TCGA-78-8662',\n",
              "  'TCGA-33-AASJ',\n",
              "  'TCGA-33-4532',\n",
              "  'TCGA-33-4583',\n",
              "  'TCGA-33-4566'],\n",
              " 'valid': []}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScrZrO2yHIG4",
        "outputId": "c501f58e-b6ea-426a-996f-6b887a094a18"
      },
      "source": [
        "''' Getting the index positions of train patches based on the data available in the filtered dataset represented in each fold generated '''\n",
        "ix_train=[]\n",
        "for x in range(5):\n",
        "  label=data[x]['train']\n",
        "  train_ix=[]\n",
        "  for i in range(179709):\n",
        "      if i < 146926:\n",
        "          if train_slides[i].decode(\"utf-8\")[0:12] in label:\n",
        "              train_ix.append(i)\n",
        "      elif i < 179709:\n",
        "          ix=i-146926\n",
        "          if valid_slides[ix].decode(\"utf-8\")[0:12] in label:\n",
        "              train_ix.append(i)\n",
        "  len(train_ix)\n",
        "  ix_train.append(train_ix)\n",
        "print(len(ix_train[2]))       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVQo7oPpHMWb",
        "outputId": "56ef48eb-a9d2-447a-99ed-2daa12712c02"
      },
      "source": [
        "''' Getting the index positions of test patches based on the data available in the filtered dataset represented in each fold generated '''\n",
        "ix_test=[]\n",
        "for x in range(5):\n",
        "  label=data[x]['test']\n",
        "  test_ix=[]\n",
        "  for i in range(179709):\n",
        "      if i < 146926:\n",
        "          if train_slides[i].decode(\"utf-8\")[0:12] in label:\n",
        "              test_ix.append(i)\n",
        "      elif i < 179709:\n",
        "          ix=i-146926\n",
        "          if valid_slides[ix].decode(\"utf-8\")[0:12] in label:\n",
        "              test_ix.append(i)\n",
        "  len(test_ix)\n",
        "  ix_test.append(test_ix)\n",
        "print(len(ix_test[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCgSlOfsHO6Q",
        "outputId": "9ec73a82-7441-4cb6-d31b-61cfe31120df"
      },
      "source": [
        "''' Model Training phase '''\n",
        "print('\\nInit Loaders...')\n",
        "print('Init Model')\n",
        "model = Attention()\n",
        "model.cuda()\n",
        "print('\\nInit optimizer ...', end=' ')\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "epoch = 1\n",
        "\n",
        "for i in range(epoch):\n",
        "    print(\"...Train...\")\n",
        "    for x in range(5):\n",
        "      train_data = InputData(train_image=dtrain,valid_image=dvalid,pos=ix_train[x])   \n",
        "      test_data = InputData(train_image=dtrain,valid_image=dvalid,pos=ix_test[x])\n",
        "      train_loader = torch.utils.data.DataLoader(train_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "      test_loader = torch.utils.data.DataLoader(test_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "      train_loop_survival(i,model,train_loader,optimizer)\n",
        "      validate_survival(1,model,test_loader)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Init Loaders...\n",
            "Init Model\n",
            "\n",
            "Init optimizer ... ...Train...\n",
            "\n",
            "\n",
            "batch 999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 1999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 2999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 3999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 4999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 5999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 6999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 7999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 8999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 9999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 10999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 11999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 12999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 13999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 14999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 15999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 16999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 17999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 18999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 19999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 20999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 21999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 22999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 23999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 24999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 25999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 26999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 27999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 28999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 29999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 30999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 31999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 32999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 33999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 34999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 35999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 36999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 37999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 38999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 39999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 65999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 66999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 67999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 68999, loss: 2.3929, risk: -0.9086, bag_size: 1\n",
            "batch 69999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 70999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 71999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 72999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 73999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 74999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 75999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 76999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 77999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 78999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 79999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 80999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 81999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 82999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 83999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 84999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 85999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 86999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 87999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 88999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 89999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 90999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 91999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 102999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 103999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 104999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 105999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 106999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 107999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 108999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 109999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 110999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 111999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 112999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 113999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 114999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 115999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 116999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 117999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 118999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 119999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 120999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 121999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 122999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 123999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 124999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 125999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 126999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 127999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 128999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 129999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 130999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 131999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 132999, loss: 2.3943, risk: -0.9088, bag_size: 1\n",
            "batch 133999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 134999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 136999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 137999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 138999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 139999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 140999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.3951, train_loss: 2.3951, train_c_index: 0.5013\n",
            "Epoch: 1, val_loss_surv: 2.7296, val_loss: 2.7296, val_c_index: 0.4987\n",
            "\n",
            "\n",
            "batch 999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 1999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 2999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 3999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 4999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 5999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 6999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 7999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.0762, risk: -0.9369, bag_size: 1\n",
            "batch 65999, loss: 2.2946, risk: -0.8509, bag_size: 1\n",
            "batch 66999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 67999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 68999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 69999, loss: 2.2946, risk: -0.8509, bag_size: 1\n",
            "batch 70999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 71999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 72999, loss: 2.2946, risk: -0.8509, bag_size: 1\n",
            "batch 73999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 74999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 75999, loss: 1.6996, risk: -0.8509, bag_size: 1\n",
            "batch 76999, loss: 1.6996, risk: -0.8508, bag_size: 1\n",
            "batch 77999, loss: 1.6996, risk: -0.8508, bag_size: 1\n",
            "batch 78999, loss: 1.6996, risk: -0.8508, bag_size: 1\n",
            "batch 79999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 80999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 81999, loss: 2.7712, risk: -0.9374, bag_size: 1\n",
            "batch 82999, loss: 2.4013, risk: -0.9094, bag_size: 1\n",
            "batch 83999, loss: 2.5725, risk: -0.9235, bag_size: 1\n",
            "batch 84999, loss: 2.4698, risk: -0.9154, bag_size: 1\n",
            "batch 85999, loss: 2.5976, risk: -0.9221, bag_size: 1\n",
            "batch 86999, loss: 2.5731, risk: -0.9237, bag_size: 1\n",
            "batch 87999, loss: 2.5801, risk: -0.9230, bag_size: 1\n",
            "batch 88999, loss: 2.5008, risk: -0.9180, bag_size: 1\n",
            "batch 89999, loss: 2.6209, risk: -0.9208, bag_size: 1\n",
            "batch 90999, loss: 2.5322, risk: -0.9205, bag_size: 1\n",
            "batch 91999, loss: 2.4964, risk: -0.9176, bag_size: 1\n",
            "batch 92999, loss: 2.6539, risk: -0.9191, bag_size: 1\n",
            "batch 93999, loss: 2.5074, risk: -0.9185, bag_size: 1\n",
            "batch 94999, loss: 2.5156, risk: -0.9192, bag_size: 1\n",
            "batch 95999, loss: 2.5198, risk: -0.9195, bag_size: 1\n",
            "batch 96999, loss: 2.5414, risk: -0.9212, bag_size: 1\n",
            "batch 97999, loss: 2.5327, risk: -0.9205, bag_size: 1\n",
            "batch 98999, loss: 2.5141, risk: -0.9191, bag_size: 1\n",
            "batch 99999, loss: 2.5252, risk: -0.9200, bag_size: 1\n",
            "batch 100999, loss: 2.5253, risk: -0.9200, bag_size: 1\n",
            "batch 101999, loss: 2.6313, risk: -0.9202, bag_size: 1\n",
            "batch 102999, loss: 2.5030, risk: -0.9182, bag_size: 1\n",
            "batch 103999, loss: 2.7269, risk: -0.9154, bag_size: 1\n",
            "batch 104999, loss: 2.6546, risk: -0.9190, bag_size: 1\n",
            "batch 105999, loss: 2.6645, risk: -0.9185, bag_size: 1\n",
            "batch 106999, loss: 2.6924, risk: -0.9171, bag_size: 1\n",
            "batch 107999, loss: 2.4999, risk: -0.9179, bag_size: 1\n",
            "batch 108999, loss: 2.6196, risk: -0.9208, bag_size: 1\n",
            "batch 109999, loss: 2.5055, risk: -0.9184, bag_size: 1\n",
            "batch 110999, loss: 2.5484, risk: -0.9218, bag_size: 1\n",
            "batch 111999, loss: 2.5420, risk: -0.9213, bag_size: 1\n",
            "batch 112999, loss: 2.6458, risk: -0.9195, bag_size: 1\n",
            "batch 113999, loss: 2.5235, risk: -0.9198, bag_size: 1\n",
            "batch 114999, loss: 2.5141, risk: -0.9191, bag_size: 1\n",
            "batch 115999, loss: 2.4766, risk: -0.9160, bag_size: 1\n",
            "batch 116999, loss: 2.5074, risk: -0.9185, bag_size: 1\n",
            "batch 117999, loss: 2.6802, risk: -0.9177, bag_size: 1\n",
            "batch 118999, loss: 2.5236, risk: -0.9198, bag_size: 1\n",
            "batch 119999, loss: 2.5377, risk: -0.9209, bag_size: 1\n",
            "batch 120999, loss: 2.5287, risk: -0.9202, bag_size: 1\n",
            "batch 121999, loss: 2.5342, risk: -0.9207, bag_size: 1\n",
            "batch 122999, loss: 2.5492, risk: -0.9218, bag_size: 1\n",
            "batch 123999, loss: 2.5750, risk: -0.9238, bag_size: 1\n",
            "batch 124999, loss: 2.5911, risk: -0.9224, bag_size: 1\n",
            "batch 125999, loss: 2.5511, risk: -0.9220, bag_size: 1\n",
            "batch 126999, loss: 2.5327, risk: -0.9205, bag_size: 1\n",
            "batch 127999, loss: 2.5217, risk: -0.9197, bag_size: 1\n",
            "batch 128999, loss: 2.6529, risk: -0.9191, bag_size: 1\n",
            "batch 129999, loss: 2.6211, risk: -0.9208, bag_size: 1\n",
            "batch 130999, loss: 2.5241, risk: -0.9199, bag_size: 1\n",
            "batch 131999, loss: 2.5414, risk: -0.9212, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.1800, train_loss: 2.1800, train_c_index: 0.4092\n",
            "Epoch: 1, val_loss_surv: 2.5888, val_loss: 2.5888, val_c_index: 0.4975\n",
            "\n",
            "\n",
            "batch 999, loss: 2.8814, risk: -0.9087, bag_size: 1\n",
            "batch 1999, loss: 2.4113, risk: -0.9103, bag_size: 1\n",
            "batch 2999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 65999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 66999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 67999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 68999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 69999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 70999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 71999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 72999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 73999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 74999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 75999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 76999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 77999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 78999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 79999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 80999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 81999, loss: 2.3928, risk: -0.9086, bag_size: 1\n",
            "batch 82999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 83999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 84999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 85999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 86999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 87999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 88999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 89999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 90999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 91999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 102999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 103999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 104999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 105999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 106999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 107999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 108999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 109999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 110999, loss: 2.4609, risk: -0.9146, bag_size: 1\n",
            "batch 111999, loss: 2.5581, risk: -0.9213, bag_size: 1\n",
            "batch 112999, loss: 2.5852, risk: -0.9224, bag_size: 1\n",
            "batch 113999, loss: 2.5254, risk: -0.9200, bag_size: 1\n",
            "batch 114999, loss: 2.5334, risk: -0.9206, bag_size: 1\n",
            "batch 115999, loss: 2.4525, risk: -0.9139, bag_size: 1\n",
            "batch 116999, loss: 2.5096, risk: -0.9186, bag_size: 1\n",
            "batch 117999, loss: 2.6851, risk: -0.9175, bag_size: 1\n",
            "batch 118999, loss: 2.5182, risk: -0.9194, bag_size: 1\n",
            "batch 119999, loss: 2.5512, risk: -0.9219, bag_size: 1\n",
            "batch 120999, loss: 2.5434, risk: -0.9214, bag_size: 1\n",
            "batch 121999, loss: 2.5409, risk: -0.9212, bag_size: 1\n",
            "batch 122999, loss: 2.5561, risk: -0.9224, bag_size: 1\n",
            "batch 123999, loss: 2.5911, risk: -0.9251, bag_size: 1\n",
            "batch 124999, loss: 2.6033, risk: -0.9217, bag_size: 1\n",
            "batch 125999, loss: 2.5534, risk: -0.9221, bag_size: 1\n",
            "batch 126999, loss: 2.5287, risk: -0.9202, bag_size: 1\n",
            "batch 127999, loss: 2.5244, risk: -0.9199, bag_size: 1\n",
            "batch 128999, loss: 2.6290, risk: -0.9203, bag_size: 1\n",
            "batch 129999, loss: 2.6098, risk: -0.9214, bag_size: 1\n",
            "batch 130999, loss: 2.5126, risk: -0.9189, bag_size: 1\n",
            "batch 131999, loss: 2.5466, risk: -0.9216, bag_size: 1\n",
            "batch 132999, loss: 2.4739, risk: -0.9157, bag_size: 1\n",
            "batch 133999, loss: 2.6253, risk: -0.9205, bag_size: 1\n",
            "batch 134999, loss: 2.5179, risk: -0.9194, bag_size: 1\n",
            "batch 136999, loss: 2.5982, risk: -0.9220, bag_size: 1\n",
            "batch 137999, loss: 2.6453, risk: -0.9195, bag_size: 1\n",
            "batch 138999, loss: 2.6384, risk: -0.9199, bag_size: 1\n",
            "batch 139999, loss: 2.5323, risk: -0.9205, bag_size: 1\n",
            "batch 140999, loss: 2.6438, risk: -0.9196, bag_size: 1\n",
            "batch 141999, loss: 2.4927, risk: -0.9173, bag_size: 1\n",
            "batch 142999, loss: 2.7276, risk: -0.9154, bag_size: 1\n",
            "batch 143999, loss: 2.8326, risk: -0.9107, bag_size: 1\n",
            "batch 144999, loss: 2.6952, risk: -0.9170, bag_size: 1\n",
            "batch 145999, loss: 2.7202, risk: -0.9158, bag_size: 1\n",
            "batch 146999, loss: 2.6349, risk: -0.9197, bag_size: 1\n",
            "batch 147999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 148999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 149999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.4800, train_loss: 2.4800, train_c_index: 0.3938\n",
            "Epoch: 1, val_loss_surv: 0.6375, val_loss: 0.6375, val_c_index: 0.4986\n",
            "\n",
            "\n",
            "batch 999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 1999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 2999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 65999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 66999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 67999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 68999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 69999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 70999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 71999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 72999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 73999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 74999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 75999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 76999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 77999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 78999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 79999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 80999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 81999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 82999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 83999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 84999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 85999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 86999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 87999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 88999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 89999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 90999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 91999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 102999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 103999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 104999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 105999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 106999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 107999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 108999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 109999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 110999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 111999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 112999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 113999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 114999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 115999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 116999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 117999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 118999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 119999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 120999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 121999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 122999, loss: 2.3943, risk: -0.9088, bag_size: 1\n",
            "batch 123999, loss: 2.5647, risk: -0.9217, bag_size: 1\n",
            "batch 124999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 125999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 126999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 127999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 128999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 129999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 130999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 131999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 132999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 133999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 134999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.5146, train_loss: 2.5146, train_c_index: 0.4177\n",
            "Epoch: 1, val_loss_surv: 2.4820, val_loss: 2.4820, val_c_index: 0.4994\n",
            "\n",
            "\n",
            "batch 999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 1999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 2999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 1.0100, risk: -0.7227, bag_size: 1\n",
            "batch 65999, loss: 1.6887, risk: -0.7386, bag_size: 1\n",
            "batch 66999, loss: 1.0064, risk: -0.7298, bag_size: 1\n",
            "batch 67999, loss: 1.0064, risk: -0.7298, bag_size: 1\n",
            "batch 68999, loss: 1.0064, risk: -0.7300, bag_size: 1\n",
            "batch 69999, loss: 1.7043, risk: -0.7247, bag_size: 1\n",
            "batch 70999, loss: 1.0064, risk: -0.7321, bag_size: 1\n",
            "batch 71999, loss: 1.0064, risk: -0.7320, bag_size: 1\n",
            "batch 72999, loss: 1.7054, risk: -0.7319, bag_size: 1\n",
            "batch 73999, loss: 1.0064, risk: -0.7316, bag_size: 1\n",
            "batch 74999, loss: 1.0064, risk: -0.7315, bag_size: 1\n",
            "batch 75999, loss: 1.0064, risk: -0.7314, bag_size: 1\n",
            "batch 76999, loss: 1.0064, risk: -0.7310, bag_size: 1\n",
            "batch 77999, loss: 1.0064, risk: -0.7312, bag_size: 1\n",
            "batch 78999, loss: 1.0064, risk: -0.7325, bag_size: 1\n",
            "batch 79999, loss: 1.7054, risk: -0.7266, bag_size: 1\n",
            "batch 80999, loss: 1.2072, risk: -0.8516, bag_size: 1\n",
            "batch 81999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 82999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 83999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 84999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 85999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 86999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 87999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 88999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 89999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 90999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 91999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 102999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 103999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 104999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 105999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 106999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 107999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 108999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 109999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 110999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 111999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 112999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 113999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 114999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 115999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 116999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 117999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 118999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 119999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 120999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 121999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 122999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 123999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 124999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 125999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 126999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 127999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 128999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 129999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 130999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 131999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 132999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 133999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 134999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 136999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 137999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 138999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 139999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 140999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 141999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 142999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 143999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 144999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 145999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 146999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 147999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 148999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 149999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 150999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 151999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 152999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.1954, train_loss: 2.1954, train_c_index: 0.4191\n",
            "Epoch: 1, val_loss_surv: 0.6217, val_loss: 0.6217, val_c_index: 0.4987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2mxW9IvHSIu"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/propro/model_updc_kfold_epoch8_nov29.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM46eMp5HVWR",
        "outputId": "fac3b343-ad0f-49a1-a6d4-1b45b93ef334"
      },
      "source": [
        "''' Continue training from the loaded model parameters '''\n",
        "print('Init Model')\n",
        "model = Attention()\n",
        "model.cuda()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/propro/model_updc_kfold_epoch7_nov27.pt'))\n",
        "print('\\nInit optimizer ...', end=' ')\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "epoch = 1\n",
        "\n",
        "for i in range(epoch):\n",
        "    print(\"...Train...\")\n",
        "    for x in range(5):\n",
        "      train_data = InputData(train_image=dtrain,valid_image=dvalid,pos=ix_train[x])   \n",
        "      test_data = InputData(train_image=dtrain,valid_image=dvalid,pos=ix_test[x])\n",
        "      train_loader = torch.utils.data.DataLoader(train_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "      test_loader = torch.utils.data.DataLoader(test_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "      train_loop_survival(i,model,train_loader,optimizer)\n",
        "      validate_survival(1,model,test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init Model\n",
            "\n",
            "Init optimizer ... ...Train...\n",
            "\n",
            "\n",
            "batch 999, loss: 2.6749, risk: -0.9180, bag_size: 1\n",
            "batch 1999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 2999, loss: 1.1784, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 1.1784, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 1.3863, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 1.3863, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 1.1784, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 65999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 66999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 67999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 68999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 69999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 70999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 71999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 72999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 73999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 74999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 75999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 76999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 77999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 78999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 79999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 80999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 81999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 82999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 83999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 84999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 85999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 86999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 87999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 88999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 89999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 90999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 91999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3929, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 102999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 103999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 104999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 105999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 106999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 107999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 108999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 109999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 110999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 111999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 112999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 113999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 114999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 115999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 116999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 117999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 118999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 119999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 120999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 121999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 122999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 123999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 124999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 125999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 126999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 127999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 128999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 129999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 130999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 131999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 132999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 133999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 134999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 136999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 137999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 138999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 139999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 140999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 141999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 142999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 143999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 144999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 145999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 146999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 1.6645, train_loss: 1.6645, train_c_index: 0.4570\n",
            "Epoch: 1, val_loss_surv: 0.6212, val_loss: 0.6212, val_c_index: 0.4986\n",
            "\n",
            "\n",
            "batch 999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 1999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 2999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 0.6931, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 0.5892, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 65999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 66999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 67999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 68999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 69999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 70999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 71999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 72999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 73999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 74999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 75999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 76999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 77999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 78999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 79999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 80999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 81999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 82999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 83999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 84999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 85999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 86999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 87999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 88999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 89999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 90999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 91999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 92999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 93999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 94999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 95999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 96999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 97999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 98999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 99999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 100999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 101999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 102999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 103999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 104999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 105999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 106999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 107999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 108999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 109999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 110999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 111999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 112999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 113999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 114999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 115999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 116999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 117999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 118999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 119999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 120999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 121999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 122999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 123999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 124999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 125999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 126999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 127999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 128999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 129999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 130999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 131999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 132999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 133999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 134999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 136999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 137999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 138999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 139999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 140999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 141999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 142999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 143999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 144999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.4080, train_loss: 2.4080, train_c_index: 0.4018\n",
            "Epoch: 1, val_loss_surv: 2.7282, val_loss: 2.7282, val_c_index: 0.4986\n",
            "\n",
            "\n",
            "batch 999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 1999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 2999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 3999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 4999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 5999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 6999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 7999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 8999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 9999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 10999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 11999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 12999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 13999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 14999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 15999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 16999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 17999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 18999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 19999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 20999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 21999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 22999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 23999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 24999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 25999, loss: 2.8838, risk: -0.9086, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.0794, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 1.7675, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 65999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 66999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 67999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 68999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 69999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 70999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 71999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 72999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 73999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 74999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 75999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 76999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 77999, loss: 2.3927, risk: -0.9086, bag_size: 1\n",
            "batch 78999, loss: 2.4552, risk: -0.9141, bag_size: 1\n",
            "batch 79999, loss: 2.6055, risk: -0.9216, bag_size: 1\n",
            "batch 80999, loss: 2.5753, risk: -0.9239, bag_size: 1\n",
            "batch 81999, loss: 2.6206, risk: -0.9272, bag_size: 1\n",
            "batch 82999, loss: 2.3978, risk: -0.9091, bag_size: 1\n",
            "batch 83999, loss: 2.5881, risk: -0.9226, bag_size: 1\n",
            "batch 84999, loss: 2.4760, risk: -0.9159, bag_size: 1\n",
            "batch 85999, loss: 2.5930, risk: -0.9223, bag_size: 1\n",
            "batch 86999, loss: 2.5614, risk: -0.9228, bag_size: 1\n",
            "batch 87999, loss: 2.5847, risk: -0.9226, bag_size: 1\n",
            "batch 88999, loss: 2.5084, risk: -0.9186, bag_size: 1\n",
            "batch 89999, loss: 2.6226, risk: -0.9207, bag_size: 1\n",
            "batch 90999, loss: 2.5347, risk: -0.9207, bag_size: 1\n",
            "batch 91999, loss: 2.5140, risk: -0.9190, bag_size: 1\n",
            "batch 92999, loss: 2.6549, risk: -0.9190, bag_size: 1\n",
            "batch 93999, loss: 2.5132, risk: -0.9190, bag_size: 1\n",
            "batch 94999, loss: 2.5233, risk: -0.9197, bag_size: 1\n",
            "batch 95999, loss: 2.5212, risk: -0.9196, bag_size: 1\n",
            "batch 96999, loss: 2.5411, risk: -0.9212, bag_size: 1\n",
            "batch 97999, loss: 2.5229, risk: -0.9197, bag_size: 1\n",
            "batch 98999, loss: 2.5171, risk: -0.9193, bag_size: 1\n",
            "batch 99999, loss: 2.5258, risk: -0.9200, bag_size: 1\n",
            "batch 100999, loss: 2.5260, risk: -0.9200, bag_size: 1\n",
            "batch 101999, loss: 2.6317, risk: -0.9202, bag_size: 1\n",
            "batch 102999, loss: 2.5047, risk: -0.9183, bag_size: 1\n",
            "batch 103999, loss: 2.7267, risk: -0.9154, bag_size: 1\n",
            "batch 104999, loss: 2.6610, risk: -0.9187, bag_size: 1\n",
            "batch 105999, loss: 2.6561, risk: -0.9189, bag_size: 1\n",
            "batch 106999, loss: 2.6867, risk: -0.9174, bag_size: 1\n",
            "batch 107999, loss: 2.4993, risk: -0.9179, bag_size: 1\n",
            "batch 108999, loss: 2.6219, risk: -0.9207, bag_size: 1\n",
            "batch 109999, loss: 2.5062, risk: -0.9184, bag_size: 1\n",
            "batch 110999, loss: 2.5439, risk: -0.9214, bag_size: 1\n",
            "batch 111999, loss: 2.5405, risk: -0.9212, bag_size: 1\n",
            "batch 112999, loss: 2.6418, risk: -0.9196, bag_size: 1\n",
            "batch 113999, loss: 2.5237, risk: -0.9198, bag_size: 1\n",
            "batch 114999, loss: 2.5161, risk: -0.9192, bag_size: 1\n",
            "batch 115999, loss: 2.4659, risk: -0.9151, bag_size: 1\n",
            "batch 116999, loss: 2.5134, risk: -0.9190, bag_size: 1\n",
            "batch 117999, loss: 2.6811, risk: -0.9177, bag_size: 1\n",
            "batch 118999, loss: 2.5228, risk: -0.9198, bag_size: 1\n",
            "batch 119999, loss: 2.5335, risk: -0.9206, bag_size: 1\n",
            "batch 120999, loss: 2.5269, risk: -0.9201, bag_size: 1\n",
            "batch 121999, loss: 2.5323, risk: -0.9205, bag_size: 1\n",
            "batch 122999, loss: 2.5490, risk: -0.9218, bag_size: 1\n",
            "batch 123999, loss: 2.5908, risk: -0.9250, bag_size: 1\n",
            "batch 124999, loss: 2.6068, risk: -0.9215, bag_size: 1\n",
            "batch 125999, loss: 2.5498, risk: -0.9219, bag_size: 1\n",
            "batch 126999, loss: 2.5318, risk: -0.9205, bag_size: 1\n",
            "batch 127999, loss: 2.5219, risk: -0.9197, bag_size: 1\n",
            "batch 128999, loss: 2.6454, risk: -0.9195, bag_size: 1\n",
            "batch 129999, loss: 2.6235, risk: -0.9207, bag_size: 1\n",
            "batch 130999, loss: 2.5276, risk: -0.9201, bag_size: 1\n",
            "batch 131999, loss: 2.5389, risk: -0.9210, bag_size: 1\n",
            "batch 132999, loss: 2.5187, risk: -0.9194, bag_size: 1\n",
            "batch 133999, loss: 2.6343, risk: -0.9200, bag_size: 1\n",
            "batch 134999, loss: 2.5161, risk: -0.9192, bag_size: 1\n",
            "batch 136999, loss: 2.6087, risk: -0.9215, bag_size: 1\n",
            "batch 137999, loss: 2.6255, risk: -0.9206, bag_size: 1\n",
            "batch 138999, loss: 2.6426, risk: -0.9197, bag_size: 1\n",
            "batch 139999, loss: 2.5241, risk: -0.9199, bag_size: 1\n",
            "batch 140999, loss: 2.6450, risk: -0.9195, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.4032, train_loss: 2.4032, train_c_index: 0.4870\n",
            "Epoch: 1, val_loss_surv: 2.6041, val_loss: 2.6041, val_c_index: 0.4987\n",
            "\n",
            "\n",
            "batch 999, loss: 2.7452, risk: -0.9146, bag_size: 1\n",
            "batch 1999, loss: 2.5095, risk: -0.9187, bag_size: 1\n",
            "batch 2999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.6610, risk: -0.9301, bag_size: 1\n",
            "batch 65999, loss: 2.6460, risk: -0.9195, bag_size: 1\n",
            "batch 66999, loss: 2.5146, risk: -0.9191, bag_size: 1\n",
            "batch 67999, loss: 2.5440, risk: -0.9214, bag_size: 1\n",
            "batch 68999, loss: 2.5435, risk: -0.9214, bag_size: 1\n",
            "batch 69999, loss: 2.6232, risk: -0.9207, bag_size: 1\n",
            "batch 70999, loss: 2.5109, risk: -0.9188, bag_size: 1\n",
            "batch 71999, loss: 2.4985, risk: -0.9178, bag_size: 1\n",
            "batch 72999, loss: 2.6091, risk: -0.9214, bag_size: 1\n",
            "batch 73999, loss: 2.4939, risk: -0.9174, bag_size: 1\n",
            "batch 74999, loss: 2.5111, risk: -0.9188, bag_size: 1\n",
            "batch 75999, loss: 2.5184, risk: -0.9194, bag_size: 1\n",
            "batch 76999, loss: 2.4900, risk: -0.9171, bag_size: 1\n",
            "batch 77999, loss: 2.4671, risk: -0.9152, bag_size: 1\n",
            "batch 78999, loss: 2.5378, risk: -0.9209, bag_size: 1\n",
            "batch 79999, loss: 2.6080, risk: -0.9215, bag_size: 1\n",
            "batch 80999, loss: 2.5286, risk: -0.9202, bag_size: 1\n",
            "batch 81999, loss: 2.5379, risk: -0.9210, bag_size: 1\n",
            "batch 82999, loss: 2.5050, risk: -0.9183, bag_size: 1\n",
            "batch 83999, loss: 2.6423, risk: -0.9197, bag_size: 1\n",
            "batch 84999, loss: 2.5057, risk: -0.9184, bag_size: 1\n",
            "batch 85999, loss: 2.6235, risk: -0.9207, bag_size: 1\n",
            "batch 86999, loss: 2.5413, risk: -0.9212, bag_size: 1\n",
            "batch 87999, loss: 2.5841, risk: -0.9228, bag_size: 1\n",
            "batch 88999, loss: 2.5073, risk: -0.9185, bag_size: 1\n",
            "batch 89999, loss: 2.6237, risk: -0.9207, bag_size: 1\n",
            "batch 90999, loss: 2.5323, risk: -0.9205, bag_size: 1\n",
            "batch 91999, loss: 2.4942, risk: -0.9174, bag_size: 1\n",
            "batch 92999, loss: 2.6447, risk: -0.9195, bag_size: 1\n",
            "batch 93999, loss: 2.5100, risk: -0.9187, bag_size: 1\n",
            "batch 94999, loss: 2.5099, risk: -0.9187, bag_size: 1\n",
            "batch 95999, loss: 2.5192, risk: -0.9195, bag_size: 1\n",
            "batch 96999, loss: 2.5373, risk: -0.9209, bag_size: 1\n",
            "batch 97999, loss: 2.5704, risk: -0.9235, bag_size: 1\n",
            "batch 98999, loss: 2.5150, risk: -0.9191, bag_size: 1\n",
            "batch 99999, loss: 2.5159, risk: -0.9192, bag_size: 1\n",
            "batch 100999, loss: 2.5162, risk: -0.9192, bag_size: 1\n",
            "batch 101999, loss: 2.6353, risk: -0.9200, bag_size: 1\n",
            "batch 102999, loss: 2.4991, risk: -0.9178, bag_size: 1\n",
            "batch 103999, loss: 2.7403, risk: -0.9148, bag_size: 1\n",
            "batch 104999, loss: 2.6612, risk: -0.9187, bag_size: 1\n",
            "batch 105999, loss: 2.6514, risk: -0.9192, bag_size: 1\n",
            "batch 106999, loss: 2.6767, risk: -0.9179, bag_size: 1\n",
            "batch 107999, loss: 2.5027, risk: -0.9181, bag_size: 1\n",
            "batch 108999, loss: 2.6259, risk: -0.9205, bag_size: 1\n",
            "batch 109999, loss: 2.5095, risk: -0.9187, bag_size: 1\n",
            "batch 110999, loss: 2.5406, risk: -0.9212, bag_size: 1\n",
            "batch 111999, loss: 2.5374, risk: -0.9209, bag_size: 1\n",
            "batch 112999, loss: 2.6440, risk: -0.9196, bag_size: 1\n",
            "batch 113999, loss: 2.5235, risk: -0.9198, bag_size: 1\n",
            "batch 114999, loss: 2.5162, risk: -0.9192, bag_size: 1\n",
            "batch 115999, loss: 2.4818, risk: -0.9164, bag_size: 1\n",
            "batch 116999, loss: 2.5068, risk: -0.9185, bag_size: 1\n",
            "batch 117999, loss: 2.6782, risk: -0.9178, bag_size: 1\n",
            "batch 118999, loss: 2.5217, risk: -0.9197, bag_size: 1\n",
            "batch 119999, loss: 2.5311, risk: -0.9204, bag_size: 1\n",
            "batch 120999, loss: 2.5259, risk: -0.9200, bag_size: 1\n",
            "batch 121999, loss: 2.5297, risk: -0.9203, bag_size: 1\n",
            "batch 122999, loss: 2.5407, risk: -0.9212, bag_size: 1\n",
            "batch 123999, loss: 2.5928, risk: -0.9252, bag_size: 1\n",
            "batch 124999, loss: 2.6030, risk: -0.9218, bag_size: 1\n",
            "batch 125999, loss: 2.5465, risk: -0.9216, bag_size: 1\n",
            "batch 126999, loss: 2.5370, risk: -0.9209, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.5153, train_loss: 2.5153, train_c_index: 0.3955\n",
            "Epoch: 1, val_loss_surv: 2.6013, val_loss: 2.6013, val_c_index: 0.4977\n",
            "\n",
            "\n",
            "batch 999, loss: 2.7569, risk: -0.9140, bag_size: 1\n",
            "batch 1999, loss: 2.5104, risk: -0.9188, bag_size: 1\n",
            "batch 2999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 3999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 4999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 5999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 6999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 7999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 8999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 9999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 10999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 11999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 12999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 13999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 14999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 15999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 16999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 17999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 18999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 19999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 20999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 21999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 22999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 23999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 24999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 25999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 26999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 27999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 28999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 29999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 30999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 31999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 32999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 33999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 34999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 35999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 36999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 37999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 38999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 39999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 40999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 41999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 42999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 43999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 44999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 45999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 46999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 47999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 48999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 49999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 50999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 51999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 52999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 53999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 54999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 55999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 56999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 57999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 58999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 59999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 60999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 61999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 62999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 63999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 64999, loss: 2.7475, risk: -0.9359, bag_size: 1\n",
            "batch 65999, loss: 2.6617, risk: -0.9187, bag_size: 1\n",
            "batch 66999, loss: 2.5367, risk: -0.9209, bag_size: 1\n",
            "batch 67999, loss: 2.6289, risk: -0.9278, bag_size: 1\n",
            "batch 68999, loss: 2.6389, risk: -0.9283, bag_size: 1\n",
            "batch 69999, loss: 2.6384, risk: -0.9199, bag_size: 1\n",
            "batch 70999, loss: 2.5050, risk: -0.9183, bag_size: 1\n",
            "batch 71999, loss: 2.4923, risk: -0.9173, bag_size: 1\n",
            "batch 72999, loss: 2.6183, risk: -0.9209, bag_size: 1\n",
            "batch 73999, loss: 2.5068, risk: -0.9185, bag_size: 1\n",
            "batch 74999, loss: 2.5193, risk: -0.9195, bag_size: 1\n",
            "batch 75999, loss: 2.5306, risk: -0.9204, bag_size: 1\n",
            "batch 76999, loss: 2.4937, risk: -0.9174, bag_size: 1\n",
            "batch 77999, loss: 2.4694, risk: -0.9154, bag_size: 1\n",
            "batch 78999, loss: 2.5374, risk: -0.9209, bag_size: 1\n",
            "batch 79999, loss: 2.6080, risk: -0.9215, bag_size: 1\n",
            "batch 80999, loss: 2.5326, risk: -0.9205, bag_size: 1\n",
            "batch 81999, loss: 2.5376, risk: -0.9209, bag_size: 1\n",
            "batch 82999, loss: 2.4925, risk: -0.9173, bag_size: 1\n",
            "batch 83999, loss: 2.6355, risk: -0.9200, bag_size: 1\n",
            "batch 84999, loss: 2.5067, risk: -0.9185, bag_size: 1\n",
            "batch 85999, loss: 2.6239, risk: -0.9206, bag_size: 1\n",
            "batch 86999, loss: 2.5489, risk: -0.9218, bag_size: 1\n",
            "batch 87999, loss: 2.5854, risk: -0.9227, bag_size: 1\n",
            "batch 88999, loss: 2.5354, risk: -0.9208, bag_size: 1\n",
            "batch 89999, loss: 2.6223, risk: -0.9207, bag_size: 1\n",
            "batch 90999, loss: 2.5367, risk: -0.9209, bag_size: 1\n",
            "batch 91999, loss: 2.5034, risk: -0.9182, bag_size: 1\n",
            "batch 92999, loss: 2.6413, risk: -0.9197, bag_size: 1\n",
            "batch 93999, loss: 2.5153, risk: -0.9192, bag_size: 1\n",
            "batch 94999, loss: 2.5186, risk: -0.9194, bag_size: 1\n",
            "batch 95999, loss: 2.5214, risk: -0.9196, bag_size: 1\n",
            "batch 96999, loss: 2.5330, risk: -0.9206, bag_size: 1\n",
            "batch 97999, loss: 2.5290, risk: -0.9203, bag_size: 1\n",
            "batch 98999, loss: 2.5218, risk: -0.9197, bag_size: 1\n",
            "batch 99999, loss: 2.5270, risk: -0.9201, bag_size: 1\n",
            "batch 100999, loss: 2.5290, risk: -0.9203, bag_size: 1\n",
            "batch 101999, loss: 2.6288, risk: -0.9204, bag_size: 1\n",
            "batch 102999, loss: 2.5026, risk: -0.9181, bag_size: 1\n",
            "batch 103999, loss: 2.7419, risk: -0.9147, bag_size: 1\n",
            "batch 104999, loss: 2.6544, risk: -0.9190, bag_size: 1\n",
            "batch 105999, loss: 2.6633, risk: -0.9186, bag_size: 1\n",
            "batch 106999, loss: 2.6859, risk: -0.9174, bag_size: 1\n",
            "batch 107999, loss: 2.5021, risk: -0.9181, bag_size: 1\n",
            "batch 108999, loss: 2.6277, risk: -0.9204, bag_size: 1\n",
            "batch 109999, loss: 2.5108, risk: -0.9188, bag_size: 1\n",
            "batch 110999, loss: 2.5384, risk: -0.9210, bag_size: 1\n",
            "batch 111999, loss: 2.5379, risk: -0.9210, bag_size: 1\n",
            "batch 112999, loss: 2.6398, risk: -0.9198, bag_size: 1\n",
            "batch 113999, loss: 2.5233, risk: -0.9198, bag_size: 1\n",
            "batch 114999, loss: 2.5147, risk: -0.9191, bag_size: 1\n",
            "batch 115999, loss: 2.4717, risk: -0.9156, bag_size: 1\n",
            "batch 116999, loss: 2.5191, risk: -0.9195, bag_size: 1\n",
            "batch 117999, loss: 2.6746, risk: -0.9180, bag_size: 1\n",
            "batch 118999, loss: 2.5247, risk: -0.9199, bag_size: 1\n",
            "batch 119999, loss: 2.5329, risk: -0.9205, bag_size: 1\n",
            "batch 120999, loss: 2.5287, risk: -0.9202, bag_size: 1\n",
            "batch 121999, loss: 2.5321, risk: -0.9205, bag_size: 1\n",
            "batch 122999, loss: 2.5420, risk: -0.9213, bag_size: 1\n",
            "batch 123999, loss: 2.5693, risk: -0.9234, bag_size: 1\n",
            "batch 124999, loss: 2.5986, risk: -0.9220, bag_size: 1\n",
            "batch 125999, loss: 2.5514, risk: -0.9220, bag_size: 1\n",
            "batch 126999, loss: 2.5388, risk: -0.9210, bag_size: 1\n",
            "batch 127999, loss: 2.5285, risk: -0.9202, bag_size: 1\n",
            "batch 128999, loss: 2.6418, risk: -0.9197, bag_size: 1\n",
            "batch 129999, loss: 2.6242, risk: -0.9206, bag_size: 1\n",
            "batch 130999, loss: 2.5281, risk: -0.9202, bag_size: 1\n",
            "batch 131999, loss: 2.5338, risk: -0.9206, bag_size: 1\n",
            "batch 132999, loss: 2.5206, risk: -0.9196, bag_size: 1\n",
            "batch 133999, loss: 2.6350, risk: -0.9200, bag_size: 1\n",
            "batch 134999, loss: 2.5094, risk: -0.9187, bag_size: 1\n",
            "batch 136999, loss: 2.6011, risk: -0.9219, bag_size: 1\n",
            "batch 137999, loss: 2.6242, risk: -0.9206, bag_size: 1\n",
            "batch 138999, loss: 2.6350, risk: -0.9200, bag_size: 1\n",
            "batch 139999, loss: 2.5209, risk: -0.9196, bag_size: 1\n",
            "batch 140999, loss: 2.6325, risk: -0.9202, bag_size: 1\n",
            "batch 141999, loss: 2.4998, risk: -0.9179, bag_size: 1\n",
            "batch 142999, loss: 2.7188, risk: -0.9158, bag_size: 1\n",
            "batch 143999, loss: 2.7930, risk: -0.9124, bag_size: 1\n",
            "batch 144999, loss: 2.7091, risk: -0.9163, bag_size: 1\n",
            "batch 145999, loss: 2.6994, risk: -0.9168, bag_size: 1\n",
            "batch 146999, loss: 2.6536, risk: -0.9191, bag_size: 1\n",
            "batch 147999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "batch 148999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 149999, loss: 2.3567, risk: -0.9375, bag_size: 1\n",
            "batch 150999, loss: 2.7726, risk: -0.9375, bag_size: 1\n",
            "Epoch: 0, train_loss_surv: 2.5145, train_loss: 2.5145, train_c_index: 0.3890\n",
            "Epoch: 1, val_loss_surv: 2.4861, val_loss: 2.4861, val_c_index: 0.4987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqp02hSc9_J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483f94e3-cddb-40c5-8208-c02b021fe728"
      },
      "source": [
        "''' Load model parameters '''\n",
        "model1=Attention()\n",
        "model1.cuda()\n",
        "model1.load_state_dict(torch.load('/content/drive/MyDrive/propro/model_updc_5fold_epoch6.pt'))\n",
        "model1.eval()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attention(\n",
              "  (feature_extractor_part1): Sequential(\n",
              "    (0): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (feature_extractor_part2): Sequential(\n",
              "    (0): Linear(in_features=140450, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (attention): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Dropout(p=0.25, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Testing model on test patches to get final performance of model '''\n",
        "filename = \"/content/drive/MyDrive/propro/hdf5_TCGAFFPE_LUAD_5x_perP_he_train.h5\"\n",
        "test = \"/content/drive/MyDrive/propro/hdf5_TCGAFFPE_LUAD_5x_perP_he_test.h5\"\n",
        "hdf5_file = h5py.File(filename, \"r\")\n",
        "hdf5_test = h5py.File(test, \"r\")\n",
        "dset = hdf5_file['train_img']\n",
        "dtest = hdf5_test['test_img']\n",
        "label = hdf5_file['train_labels']\n",
        "test_data = InputTest(image=dtest)\n",
        "print('\\nInit Loaders...')\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "validate_survival(1,model1,test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaBCsPsDqAC8",
        "outputId": "7f90f26b-c613-4680-de78-a111f4020e45"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Init Loaders...\n",
            "Epoch: 1, val_loss_surv: 1.8842, val_loss: 1.8842, val_c_index: 0.5475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Ygo6yRQrBTO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}