{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a8da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports and function to get image pathces into bags with an assigned bag label without augmentation on patches '''\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "class PatchMethod(torch.utils.data.Dataset):\n",
    "    def __init__(self, root = 'USCB/train/*/*/*/*.tif', mode = 'train', transform = None):\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.raw_samples = glob.glob(root)\n",
    "        self.samples = []\n",
    "        for raw_sample in self.raw_samples:\n",
    "            self.samples.append((raw_sample, int(raw_sample.split('\\\\')[-3])))\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            random.shuffle(self.samples)\n",
    "            \n",
    "        image_dir, label = self.samples[index]\n",
    "        images = glob.glob(image_dir)\n",
    "   \n",
    "        \n",
    "        transformations = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        array = []\n",
    "        \n",
    "        for i, image_path in enumerate(images):\n",
    "            image = Image.open(image_path)\n",
    "            image = np.array(image)\n",
    "            r, c, _ = image.shape\n",
    "            for i in range(0,32*24,32):\n",
    "                for j in range(0,32*28,32):\n",
    "                    array.append(transformations(image[i:i+32, j:j+32, :]))\n",
    "\n",
    "                    \n",
    "                    \n",
    "        array = tuple(array)\n",
    " \n",
    "        array = torch.stack(array, 0)\n",
    "        \n",
    "        return (array, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b17e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to get image pathces into bags with an assigned bag label with augmentation on patches '''\n",
    "class AugPatchMethod(torch.utils.data.Dataset):\n",
    "    def __init__(self, root = 'USCB/train/*/*/*/*.tif', mode = 'train', transform = None):\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.raw_samples = glob.glob(root)\n",
    "        self.samples = []\n",
    "        for raw_sample in self.raw_samples:\n",
    "            self.samples.append((raw_sample, int(raw_sample.split('\\\\')[-3])))\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            random.shuffle(self.samples)\n",
    "            \n",
    "        image_dir, label = self.samples[index]\n",
    "        images = glob.glob(image_dir)\n",
    "\n",
    "        \n",
    "        transformations = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=45),\n",
    "            transforms.ToTensor()            \n",
    "        ])\n",
    "        \n",
    "        array = []\n",
    "        \n",
    "        for i, image_path in enumerate(images):\n",
    "            image = Image.open(image_path)\n",
    "            image = np.array(image)\n",
    "            r, c, _ = image.shape\n",
    "            for i in range(0,32*24,32):\n",
    "                for j in range(0,32*28,32):\n",
    "                    array.append(transformations(image[i:i+32, j:j+32, :]))\n",
    "\n",
    "                    \n",
    "                    \n",
    "        array = tuple(array)\n",
    "\n",
    "        array = torch.stack(array, 0)\n",
    "        \n",
    "        return (array, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Attention model definition along with loss function and function to compute classification error '''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 500\n",
    "        self.D = 128\n",
    "        self.K = 1\n",
    "\n",
    "        self.feature_extractor_part1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 20, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(20, 50, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.feature_extractor_part2 = nn.Sequential(\n",
    "            nn.Linear(50 * 4 * 4, self.L),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(0)\n",
    "        H = self.feature_extractor_part1(x)\n",
    "        H = H.view(-1, 50 * 4 * 4)\n",
    "        H = self.feature_extractor_part2(H)  \n",
    "\n",
    "        A = self.attention(H)  \n",
    "        A = torch.transpose(A, 1, 0)  \n",
    "        A = F.softmax(A, dim=1)  \n",
    "\n",
    "        M = torch.mm(A, H)  \n",
    "\n",
    "        Y_prob = self.classifier(M)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return Y_prob, Y_hat, A\n",
    "    \n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat, _ = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _, A = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  \n",
    "\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38904a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch_100 learning_rate_0.0001\n",
      "\n",
      "GPU is ON!\n",
      "Load Train and Test Set\n",
      "Init Model\n",
      "Epoch: 1, Loss: 0.6941, Train error: 0.4875, Train accuracy: 51.25\n",
      "Epoch: 1, Loss: 0.6925, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 2, Loss: 0.6800, Train error: 0.4000, Train accuracy: 60.00\n",
      "Epoch: 2, Loss: 0.6982, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 3, Loss: 0.6870, Train error: 0.4125, Train accuracy: 58.75\n",
      "Epoch: 3, Loss: 0.6940, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 4, Loss: 0.6855, Train error: 0.4250, Train accuracy: 57.50\n",
      "Epoch: 4, Loss: 0.6921, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 5, Loss: 0.6933, Train error: 0.4875, Train accuracy: 51.25\n",
      "Epoch: 5, Loss: 0.6888, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 6, Loss: 0.6750, Train error: 0.4250, Train accuracy: 57.50\n",
      "Epoch: 6, Loss: 0.6890, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 7, Loss: 0.7066, Train error: 0.6000, Train accuracy: 40.00\n",
      "Epoch: 7, Loss: 0.6924, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 8, Loss: 0.6897, Train error: 0.4125, Train accuracy: 58.75\n",
      "Epoch: 8, Loss: 0.6902, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 9, Loss: 0.6842, Train error: 0.4875, Train accuracy: 51.25\n",
      "Epoch: 9, Loss: 0.6793, test error: 0.4250, test accuracy: 57.50\n",
      "Epoch: 10, Loss: 0.6775, Train error: 0.4500, Train accuracy: 55.00\n",
      "Epoch: 10, Loss: 0.6774, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 11, Loss: 0.6871, Train error: 0.3875, Train accuracy: 61.25\n",
      "Epoch: 11, Loss: 0.6808, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 12, Loss: 0.6946, Train error: 0.5125, Train accuracy: 48.75\n",
      "Epoch: 12, Loss: 0.6965, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 13, Loss: 0.6912, Train error: 0.4625, Train accuracy: 53.75\n",
      "Epoch: 13, Loss: 0.6961, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 14, Loss: 0.6930, Train error: 0.4750, Train accuracy: 52.50\n",
      "Epoch: 14, Loss: 0.6940, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 15, Loss: 0.6941, Train error: 0.4750, Train accuracy: 52.50\n",
      "Epoch: 15, Loss: 0.6807, test error: 0.4250, test accuracy: 57.50\n",
      "Epoch: 16, Loss: 0.6743, Train error: 0.4250, Train accuracy: 57.50\n",
      "Epoch: 16, Loss: 0.6748, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 17, Loss: 0.6705, Train error: 0.4625, Train accuracy: 53.75\n",
      "Epoch: 17, Loss: 0.6662, test error: 0.4500, test accuracy: 55.00\n",
      "Epoch: 18, Loss: 0.6522, Train error: 0.4125, Train accuracy: 58.75\n",
      "Epoch: 18, Loss: 0.6594, test error: 0.4750, test accuracy: 52.50\n",
      "Epoch: 19, Loss: 0.6709, Train error: 0.4750, Train accuracy: 52.50\n",
      "Epoch: 19, Loss: 0.6834, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 20, Loss: 0.6756, Train error: 0.3875, Train accuracy: 61.25\n",
      "Epoch: 20, Loss: 0.6660, test error: 0.3000, test accuracy: 70.00\n",
      "Epoch: 21, Loss: 0.6494, Train error: 0.3125, Train accuracy: 68.75\n",
      "Epoch: 21, Loss: 0.6742, test error: 0.5000, test accuracy: 50.00\n",
      "Epoch: 22, Loss: 0.6591, Train error: 0.3250, Train accuracy: 67.50\n",
      "Epoch: 22, Loss: 0.6276, test error: 0.2750, test accuracy: 72.50\n",
      "Epoch: 23, Loss: 0.6398, Train error: 0.3875, Train accuracy: 61.25\n",
      "Epoch: 23, Loss: 0.6243, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 24, Loss: 0.6420, Train error: 0.2625, Train accuracy: 73.75\n",
      "Epoch: 24, Loss: 0.6099, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 25, Loss: 0.6010, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 25, Loss: 0.5781, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 26, Loss: 0.6015, Train error: 0.3375, Train accuracy: 66.25\n",
      "Epoch: 26, Loss: 0.6193, test error: 0.4875, test accuracy: 51.25\n",
      "Epoch: 27, Loss: 0.5494, Train error: 0.2625, Train accuracy: 73.75\n",
      "Epoch: 27, Loss: 0.5607, test error: 0.2750, test accuracy: 72.50\n",
      "Epoch: 28, Loss: 0.5436, Train error: 0.1875, Train accuracy: 81.25\n",
      "Epoch: 28, Loss: 0.5518, test error: 0.2750, test accuracy: 72.50\n",
      "Epoch: 29, Loss: 0.5416, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 29, Loss: 0.5710, test error: 0.3125, test accuracy: 68.75\n",
      "Epoch: 30, Loss: 0.5708, Train error: 0.3250, Train accuracy: 67.50\n",
      "Epoch: 30, Loss: 0.6210, test error: 0.4375, test accuracy: 56.25\n",
      "Epoch: 31, Loss: 0.5184, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 31, Loss: 0.4966, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 32, Loss: 0.5330, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 32, Loss: 0.5128, test error: 0.2375, test accuracy: 76.25\n",
      "Epoch: 33, Loss: 0.4381, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 33, Loss: 0.4693, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 34, Loss: 0.4576, Train error: 0.2875, Train accuracy: 71.25\n",
      "Epoch: 34, Loss: 0.4832, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 35, Loss: 0.5640, Train error: 0.2750, Train accuracy: 72.50\n",
      "Epoch: 35, Loss: 0.4778, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 36, Loss: 0.5038, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 36, Loss: 0.4546, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 37, Loss: 0.5013, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 37, Loss: 0.4617, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 38, Loss: 0.5161, Train error: 0.2750, Train accuracy: 72.50\n",
      "Epoch: 38, Loss: 0.4877, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 39, Loss: 0.5146, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 39, Loss: 0.4567, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 40, Loss: 0.5281, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 40, Loss: 0.4546, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 41, Loss: 0.4190, Train error: 0.1500, Train accuracy: 85.00\n",
      "Epoch: 41, Loss: 0.4553, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 42, Loss: 0.4559, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 42, Loss: 0.5191, test error: 0.2875, test accuracy: 71.25\n",
      "Epoch: 43, Loss: 0.4718, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 43, Loss: 0.4594, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 44, Loss: 0.4780, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 44, Loss: 0.4416, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 45, Loss: 0.5446, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 45, Loss: 0.5321, test error: 0.3000, test accuracy: 70.00\n",
      "Epoch: 46, Loss: 0.5113, Train error: 0.2750, Train accuracy: 72.50\n",
      "Epoch: 46, Loss: 0.4410, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 47, Loss: 0.4465, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 47, Loss: 0.4568, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 48, Loss: 0.4590, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 48, Loss: 0.4320, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 49, Loss: 0.5001, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 49, Loss: 0.4424, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 50, Loss: 0.4194, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 50, Loss: 0.4774, test error: 0.2125, test accuracy: 78.75\n",
      "Epoch: 51, Loss: 0.5246, Train error: 0.2250, Train accuracy: 77.50\n",
      "Epoch: 51, Loss: 0.4750, test error: 0.2125, test accuracy: 78.75\n",
      "Epoch: 52, Loss: 0.4989, Train error: 0.2375, Train accuracy: 76.25\n",
      "Epoch: 52, Loss: 0.4998, test error: 0.2625, test accuracy: 73.75\n",
      "Epoch: 53, Loss: 0.3955, Train error: 0.1500, Train accuracy: 85.00\n",
      "Epoch: 53, Loss: 0.4318, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 54, Loss: 0.4224, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 54, Loss: 0.4363, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 55, Loss: 0.5069, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 55, Loss: 0.4327, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 56, Loss: 0.4093, Train error: 0.1375, Train accuracy: 86.25\n",
      "Epoch: 56, Loss: 0.4171, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 57, Loss: 0.4918, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 57, Loss: 0.4249, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 58, Loss: 0.4091, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 58, Loss: 0.4632, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 59, Loss: 0.3906, Train error: 0.1875, Train accuracy: 81.25\n",
      "Epoch: 59, Loss: 0.4411, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 60, Loss: 0.4384, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 60, Loss: 0.4158, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 61, Loss: 0.4020, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 61, Loss: 0.7493, test error: 0.4250, test accuracy: 57.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Loss: 0.5528, Train error: 0.3000, Train accuracy: 70.00\n",
      "Epoch: 62, Loss: 0.4191, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 63, Loss: 0.4397, Train error: 0.2250, Train accuracy: 77.50\n",
      "Epoch: 63, Loss: 0.4682, test error: 0.2250, test accuracy: 77.50\n",
      "Epoch: 64, Loss: 0.3698, Train error: 0.1500, Train accuracy: 85.00\n",
      "Epoch: 64, Loss: 0.4765, test error: 0.2375, test accuracy: 76.25\n",
      "Epoch: 65, Loss: 0.4524, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 65, Loss: 0.4327, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 66, Loss: 0.4542, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 66, Loss: 0.4166, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 67, Loss: 0.3625, Train error: 0.1500, Train accuracy: 85.00\n",
      "Epoch: 67, Loss: 0.3988, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 68, Loss: 0.4107, Train error: 0.1875, Train accuracy: 81.25\n",
      "Epoch: 68, Loss: 0.4112, test error: 0.1875, test accuracy: 81.25\n",
      "Epoch: 69, Loss: 0.4558, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 69, Loss: 0.4943, test error: 0.2500, test accuracy: 75.00\n",
      "Epoch: 70, Loss: 0.4727, Train error: 0.2250, Train accuracy: 77.50\n",
      "Epoch: 70, Loss: 0.4033, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 71, Loss: 0.4056, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 71, Loss: 0.4505, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 72, Loss: 0.4496, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 72, Loss: 0.4003, test error: 0.1250, test accuracy: 87.50\n",
      "Epoch: 73, Loss: 0.5001, Train error: 0.1875, Train accuracy: 81.25\n",
      "Epoch: 73, Loss: 0.3985, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 74, Loss: 0.3954, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 74, Loss: 0.4090, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 75, Loss: 0.3787, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 75, Loss: 0.3943, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 76, Loss: 0.3374, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 76, Loss: 0.5116, test error: 0.2625, test accuracy: 73.75\n",
      "Epoch: 77, Loss: 0.4835, Train error: 0.2250, Train accuracy: 77.50\n",
      "Epoch: 77, Loss: 0.4038, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 78, Loss: 0.3393, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 78, Loss: 0.3895, test error: 0.1250, test accuracy: 87.50\n",
      "Epoch: 79, Loss: 0.5041, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 79, Loss: 0.4046, test error: 0.1250, test accuracy: 87.50\n",
      "Epoch: 80, Loss: 0.4178, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 80, Loss: 0.4049, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 81, Loss: 0.4496, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 81, Loss: 0.3972, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 82, Loss: 0.4772, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 82, Loss: 0.4641, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 83, Loss: 0.3464, Train error: 0.1375, Train accuracy: 86.25\n",
      "Epoch: 83, Loss: 0.3906, test error: 0.1750, test accuracy: 82.50\n",
      "Epoch: 84, Loss: 0.3602, Train error: 0.0875, Train accuracy: 91.25\n",
      "Epoch: 84, Loss: 0.4013, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 85, Loss: 0.3952, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 85, Loss: 0.4010, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 86, Loss: 0.4358, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 86, Loss: 0.3954, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 87, Loss: 0.4323, Train error: 0.2000, Train accuracy: 80.00\n",
      "Epoch: 87, Loss: 0.4223, test error: 0.2250, test accuracy: 77.50\n",
      "Epoch: 88, Loss: 0.3726, Train error: 0.1375, Train accuracy: 86.25\n",
      "Epoch: 88, Loss: 0.3753, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 89, Loss: 0.4103, Train error: 0.1625, Train accuracy: 83.75\n",
      "Epoch: 89, Loss: 0.3696, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 90, Loss: 0.5065, Train error: 0.2500, Train accuracy: 75.00\n",
      "Epoch: 90, Loss: 0.3789, test error: 0.1250, test accuracy: 87.50\n",
      "Epoch: 91, Loss: 0.3474, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 91, Loss: 0.4622, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 92, Loss: 0.3888, Train error: 0.1375, Train accuracy: 86.25\n",
      "Epoch: 92, Loss: 0.3628, test error: 0.1500, test accuracy: 85.00\n",
      "Epoch: 93, Loss: 0.4297, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 93, Loss: 0.3933, test error: 0.1625, test accuracy: 83.75\n",
      "Epoch: 94, Loss: 0.3972, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 94, Loss: 0.3679, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 95, Loss: 0.3151, Train error: 0.1125, Train accuracy: 88.75\n",
      "Epoch: 95, Loss: 0.3547, test error: 0.1125, test accuracy: 88.75\n",
      "Epoch: 96, Loss: 0.3057, Train error: 0.1375, Train accuracy: 86.25\n",
      "Epoch: 96, Loss: 0.4628, test error: 0.2000, test accuracy: 80.00\n",
      "Epoch: 97, Loss: 0.4343, Train error: 0.2125, Train accuracy: 78.75\n",
      "Epoch: 97, Loss: 0.3868, test error: 0.1375, test accuracy: 86.25\n",
      "Epoch: 98, Loss: 0.4007, Train error: 0.1750, Train accuracy: 82.50\n",
      "Epoch: 98, Loss: 0.3481, test error: 0.1250, test accuracy: 87.50\n",
      "Epoch: 99, Loss: 0.3744, Train error: 0.1500, Train accuracy: 85.00\n",
      "Epoch: 99, Loss: 0.3498, test error: 0.1125, test accuracy: 88.75\n",
      "Epoch: 100, Loss: 0.4484, Train error: 0.1250, Train accuracy: 87.50\n",
      "Epoch: 100, Loss: 0.3704, test error: 0.1000, test accuracy: 90.00\n"
     ]
    }
   ],
   "source": [
    "''' Running the training and testing of model to get the accuracy of model '''\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import random\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='USCB-Augmented-classification')\n",
    "\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(' epoch_{} learning_rate_{}'.format( 100, 0.0001))\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(1)\n",
    "    print('\\nGPU is ON!')\n",
    "\n",
    "print('Load Train and Test Set')\n",
    "loader_kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "\n",
    "data_path_test = 'USCB/test/*/*/*/*.tif'\n",
    "original_train_data = PatchMethod()\n",
    "aug_train_data = AugPatchMethod()\n",
    "data=torch.utils.data.ConcatDataset([original_train_data,aug_train_data])\n",
    "original_val_data =PatchMethod(root = data_path_test, mode = 'test')\n",
    "aug_val_data = AugPatchMethod(root = data_path_test, mode = 'test')\n",
    "val_data=torch.utils.data.ConcatDataset([original_val_data,aug_val_data])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, shuffle = True, num_workers = 0, batch_size = 1)\n",
    "test_loader = torch.utils.data.DataLoader(val_data, shuffle = False, num_workers = 0, batch_size = 1)\n",
    "\n",
    "\n",
    "print('Init Model')\n",
    "model = Attention()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=0.0005)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    correct_label_pred = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    " \n",
    "        bag_label = label[0]\n",
    "        if args.cuda:\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        data = data.squeeze(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model.calculate_objective(data, bag_label)\n",
    "        train_loss += loss.data[0]\n",
    "        error, predicted_label_train = model.calculate_classification_error(data, bag_label)\n",
    "        correct_label_pred += (int(bag_label) == int(predicted_label_train))\n",
    "        train_error += error\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "    train_acc = (1 - train_error)*100\n",
    "\n",
    " \n",
    "\n",
    "    result_train = 'Epoch: {}, Loss: {:.4f}, Train error: {:.4f}, Train accuracy: {:.2f}'.format(epoch, train_loss.cpu().numpy()[0], train_error, train_acc)\n",
    "\n",
    "    print(result_train)\n",
    "    return result_train\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_error = 0.\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        \n",
    "\n",
    "        bag_label = label[0]\n",
    "        instance_labels = label[0]\n",
    "        if args.cuda:\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "        test_loss += loss.data[0]\n",
    "        error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "        test_error += error\n",
    "\n",
    "        \n",
    "        if batch_idx < 1: \n",
    "            bag_level = (bag_label.cpu().data.numpy(), int(predicted_label.cpu().data.numpy()))\n",
    "      \n",
    "\n",
    "    test_error /= len(test_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = (1 - test_error)*100    \n",
    "\n",
    "   \n",
    "    result_test = 'Epoch: {}, Loss: {:.4f}, test error: {:.4f}, test accuracy: {:.2f}'.format(epoch, test_loss.cpu().numpy()[0], test_error, test_acc)\n",
    "    print(result_test)\n",
    "    return result_test\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    for epoch in range(1, 100 + 1):\n",
    "        train_result = train(epoch)\n",
    "        test_result = test(epoch)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e03b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
